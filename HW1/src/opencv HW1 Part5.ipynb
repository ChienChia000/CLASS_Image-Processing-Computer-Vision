{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QDialog, QMessageBox, QPushButton\n",
    "from hw1UI import Ui_Dialog\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "OPTIMIZER = \"SGD\"\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 50000\n",
    "def downloadMNIST():\n",
    "    data_transform = transforms.Compose([transforms.Resize((32, 32)), transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    train_data = datasets.MNIST(root=\"./\", train=True,download=True, transform=data_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS)))\n",
    "    \n",
    "    val_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS, 60000)))\n",
    "\n",
    "    test_data = datasets.MNIST(root=\"./\", train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_data, train_loader, test_data, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_loader, test_data, test_loader, val_loader = downloadMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Show 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 14), num='5.1 10 Images and Labels of MNIST')\n",
    "columns = 5\n",
    "rows = 2\n",
    "for i in range(1, columns*rows +1):\n",
    "    randomNum = random.randint(0,60000)\n",
    "    train_image, train_image_label = train_data[randomNum]\n",
    "    train_image = np.array(train_image, dtype='float')\n",
    "    pixels = train_image.reshape((32, 32))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.xlabel(train_image_label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Print Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters:\n",
      "batch size: 32\n",
      "learning rate: 0.001\n",
      "optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperparameters:\")\n",
    "print(\"batch size:\", BATCH_SIZE)\n",
    "print(\"learning rate:\", LEARNING_RATE)\n",
    "print(\"optimizer:\", OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train 1 epoch and show training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS=[]\n",
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "#             print(\"---------------- Epoch {} ----------------\".format(epoch))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        global flag\n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            ###################################\n",
    "            LOSS.append(loss.data.item())\n",
    "            FIG_X.append(flag)\n",
    "            flag=flag+1\n",
    "            ###################################\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "            ####################################\n",
    "            if(state == \"Validate\"):\n",
    "                LOSS_TRAIN.append(loss)\n",
    "                ACC_TRAIN.append(self._accuracy(outs, y))\n",
    "            elif(state == \"Testing\"):\n",
    "                ACC_TEST.append(self._accuracy(outs, y))\n",
    "            ####################################\n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (sub2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (sub4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1, self.conv3 = None, None\n",
    "        self.sub2, self.sub4 = None, None\n",
    "        self.fc1, self.fc2, self.fc3 = None, None, None\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.sub2 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0, bias=True),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.sub4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.conv1(out)\n",
    "        out = self.sub2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.sub4(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 000 Loss 2.298 Acc 0.125\n",
      "[  1/1] Training Step 100 Loss 2.294 Acc 0.094\n",
      "[  1/1] Training Step 200 Loss 2.251 Acc 0.312\n",
      "[  1/1] Training Step 300 Loss 1.810 Acc 0.625\n",
      "[  1/1] Training Step 400 Loss 0.528 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.426 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.320 Acc 0.812\n",
      "[  1/1] Training Step 700 Loss 0.244 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.193 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.457 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.232 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.243 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.191 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.223 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.329 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.151 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.184 Acc 0.947\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.180 Acc 0.946\n"
     ]
    }
   ],
   "source": [
    "LOSS=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(loss_function, optimizer, device)\n",
    "trainer.train_loop(cnn, train_loader, val_loader)\n",
    "trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fdbed902910>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FIG_X[:len(LOSS)], LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (sub2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (sub4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS_TRAIN: []\n",
      "ACC_TRAIN: []\n",
      "ACC_TEST: []\n",
      "X: []\n"
     ]
    }
   ],
   "source": [
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "X=[]\n",
    "flag=0\n",
    "print(\"LOSS_TRAIN:\", LOSS_TRAIN)\n",
    "print(\"ACC_TRAIN:\",ACC_TRAIN)\n",
    "print(\"ACC_TEST:\",ACC_TEST)\n",
    "print(\"X:\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.318 Acc 0.094\n",
      "[  1/1] Training Step 100 Loss 2.308 Acc 0.031\n",
      "[  1/1] Training Step 200 Loss 2.294 Acc 0.188\n",
      "[  1/1] Training Step 300 Loss 2.305 Acc 0.094\n",
      "[  1/1] Training Step 400 Loss 2.300 Acc 0.031\n",
      "[  1/1] Training Step 500 Loss 2.310 Acc 0.062\n",
      "[  1/1] Training Step 600 Loss 2.303 Acc 0.125\n",
      "[  1/1] Training Step 700 Loss 2.289 Acc 0.250\n",
      "[  1/1] Training Step 800 Loss 2.281 Acc 0.188\n",
      "[  1/1] Training Step 900 Loss 2.311 Acc 0.000\n",
      "[  1/1] Training Step 1000 Loss 2.282 Acc 0.219\n",
      "[  1/1] Training Step 1100 Loss 2.310 Acc 0.094\n",
      "[  1/1] Training Step 1200 Loss 2.289 Acc 0.062\n",
      "[  1/1] Training Step 1300 Loss 2.305 Acc 0.031\n",
      "[  1/1] Training Step 1400 Loss 2.302 Acc 0.062\n",
      "[  1/1] Training Step 1500 Loss 2.297 Acc 0.156\n",
      "[  1/1] Validate Step 312 Loss 2.297 Acc 0.111\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.297 Acc 0.106\n",
      "---------------- Epoch 1 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.294 Acc 0.219\n",
      "[  1/1] Training Step 100 Loss 2.295 Acc 0.188\n",
      "[  1/1] Training Step 200 Loss 2.307 Acc 0.156\n",
      "[  1/1] Training Step 300 Loss 2.298 Acc 0.031\n",
      "[  1/1] Training Step 400 Loss 2.300 Acc 0.062\n",
      "[  1/1] Training Step 500 Loss 2.289 Acc 0.125\n",
      "[  1/1] Training Step 600 Loss 2.289 Acc 0.188\n",
      "[  1/1] Training Step 700 Loss 2.296 Acc 0.062\n",
      "[  1/1] Training Step 800 Loss 2.295 Acc 0.188\n",
      "[  1/1] Training Step 900 Loss 2.295 Acc 0.188\n",
      "[  1/1] Training Step 1000 Loss 2.291 Acc 0.125\n",
      "[  1/1] Training Step 1100 Loss 2.294 Acc 0.156\n",
      "[  1/1] Training Step 1200 Loss 2.289 Acc 0.281\n",
      "[  1/1] Training Step 1300 Loss 2.289 Acc 0.188\n",
      "[  1/1] Training Step 1400 Loss 2.283 Acc 0.219\n",
      "[  1/1] Training Step 1500 Loss 2.288 Acc 0.250\n",
      "[  1/1] Validate Step 312 Loss 2.284 Acc 0.243\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.284 Acc 0.243\n",
      "---------------- Epoch 2 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.288 Acc 0.250\n",
      "[  1/1] Training Step 100 Loss 2.282 Acc 0.250\n",
      "[  1/1] Training Step 200 Loss 2.277 Acc 0.281\n",
      "[  1/1] Training Step 300 Loss 2.283 Acc 0.188\n",
      "[  1/1] Training Step 400 Loss 2.280 Acc 0.250\n",
      "[  1/1] Training Step 500 Loss 2.285 Acc 0.188\n",
      "[  1/1] Training Step 600 Loss 2.269 Acc 0.406\n",
      "[  1/1] Training Step 700 Loss 2.268 Acc 0.312\n",
      "[  1/1] Training Step 800 Loss 2.258 Acc 0.375\n",
      "[  1/1] Training Step 900 Loss 2.270 Acc 0.250\n",
      "[  1/1] Training Step 1000 Loss 2.257 Acc 0.406\n",
      "[  1/1] Training Step 1100 Loss 2.246 Acc 0.562\n",
      "[  1/1] Training Step 1200 Loss 2.246 Acc 0.406\n",
      "[  1/1] Training Step 1300 Loss 2.242 Acc 0.594\n",
      "[  1/1] Training Step 1400 Loss 2.248 Acc 0.438\n",
      "[  1/1] Training Step 1500 Loss 2.230 Acc 0.500\n",
      "[  1/1] Validate Step 312 Loss 2.223 Acc 0.450\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.223 Acc 0.441\n",
      "---------------- Epoch 3 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.236 Acc 0.375\n",
      "[  1/1] Training Step 100 Loss 2.201 Acc 0.469\n",
      "[  1/1] Training Step 200 Loss 2.205 Acc 0.375\n",
      "[  1/1] Training Step 300 Loss 2.191 Acc 0.500\n",
      "[  1/1] Training Step 400 Loss 2.200 Acc 0.312\n",
      "[  1/1] Training Step 500 Loss 2.154 Acc 0.375\n",
      "[  1/1] Training Step 600 Loss 2.036 Acc 0.562\n",
      "[  1/1] Training Step 700 Loss 2.033 Acc 0.625\n",
      "[  1/1] Training Step 800 Loss 1.999 Acc 0.312\n",
      "[  1/1] Training Step 900 Loss 1.883 Acc 0.625\n",
      "[  1/1] Training Step 1000 Loss 1.732 Acc 0.594\n",
      "[  1/1] Training Step 1100 Loss 1.712 Acc 0.625\n",
      "[  1/1] Training Step 1200 Loss 1.500 Acc 0.625\n",
      "[  1/1] Training Step 1300 Loss 1.522 Acc 0.688\n",
      "[  1/1] Training Step 1400 Loss 1.320 Acc 0.750\n",
      "[  1/1] Training Step 1500 Loss 1.118 Acc 0.750\n",
      "[  1/1] Validate Step 312 Loss 1.072 Acc 0.757\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 1.067 Acc 0.742\n",
      "---------------- Epoch 4 ----------------\n",
      "[  1/1] Training Step 000 Loss 1.117 Acc 0.656\n",
      "[  1/1] Training Step 100 Loss 0.963 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.893 Acc 0.719\n",
      "[  1/1] Training Step 300 Loss 0.855 Acc 0.750\n",
      "[  1/1] Training Step 400 Loss 0.678 Acc 0.844\n",
      "[  1/1] Training Step 500 Loss 0.569 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.509 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.694 Acc 0.812\n",
      "[  1/1] Training Step 800 Loss 0.492 Acc 0.781\n",
      "[  1/1] Training Step 900 Loss 0.443 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.524 Acc 0.844\n",
      "[  1/1] Training Step 1100 Loss 0.481 Acc 0.781\n",
      "[  1/1] Training Step 1200 Loss 0.457 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.237 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.345 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.381 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.392 Acc 0.889\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.401 Acc 0.883\n",
      "---------------- Epoch 5 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.662 Acc 0.844\n",
      "[  1/1] Training Step 100 Loss 0.367 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.389 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.822 Acc 0.750\n",
      "[  1/1] Training Step 400 Loss 0.463 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.150 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.203 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.355 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.552 Acc 0.781\n",
      "[  1/1] Training Step 900 Loss 0.168 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.428 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.145 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.370 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.363 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.261 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.348 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.301 Acc 0.910\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.315 Acc 0.904\n",
      "---------------- Epoch 6 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.346 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.143 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.136 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.592 Acc 0.844\n",
      "[  1/1] Training Step 400 Loss 0.436 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.194 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.245 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.240 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.224 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.223 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.118 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.156 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.171 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.242 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.386 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.244 Acc 0.928\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.253 Acc 0.926\n",
      "---------------- Epoch 7 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.266 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.213 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.165 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.183 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.375 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.326 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.338 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.251 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.209 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.242 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.367 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.303 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.436 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.308 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.211 Acc 0.940\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.218 Acc 0.935\n",
      "---------------- Epoch 8 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.124 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.366 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.348 Acc 0.844\n",
      "[  1/1] Training Step 300 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.184 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.365 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.291 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.172 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.145 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.169 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.162 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.509 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.062 Acc 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1500 Loss 0.287 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.192 Acc 0.945\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.198 Acc 0.945\n",
      "---------------- Epoch 9 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.382 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.083 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.412 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.138 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.487 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.148 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.213 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.132 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.407 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.247 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.211 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.172 Acc 0.951\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.175 Acc 0.950\n",
      "---------------- Epoch 10 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.319 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.320 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.156 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.362 Acc 0.844\n",
      "[  1/1] Training Step 400 Loss 0.219 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.308 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.148 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.286 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.137 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.121 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.086 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.247 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.180 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.153 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.158 Acc 0.956\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.161 Acc 0.950\n",
      "---------------- Epoch 11 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.187 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.244 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.307 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.205 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.324 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.101 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.066 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.114 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.285 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.155 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.278 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.141 Acc 0.960\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.138 Acc 0.959\n",
      "---------------- Epoch 12 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.164 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.384 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.267 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.172 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.115 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.272 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.356 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.236 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.093 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.131 Acc 0.963\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.131 Acc 0.962\n",
      "---------------- Epoch 13 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.092 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.072 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.056 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.147 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.216 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.147 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.060 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.316 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.092 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.123 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.121 Acc 0.963\n",
      "---------------- Epoch 14 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.244 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.082 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.067 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.234 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.158 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.151 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.107 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.249 Acc 0.844\n",
      "[  1/1] Training Step 1300 Loss 0.157 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.288 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.045 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.114 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.111 Acc 0.967\n",
      "---------------- Epoch 15 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.104 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.062 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.063 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.151 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.099 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.032 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.116 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.111 Acc 0.965\n",
      "---------------- Epoch 16 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.156 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.234 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.073 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.225 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.091 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.070 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.106 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.228 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.079 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.245 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.060 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.103 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.099 Acc 0.971\n",
      "---------------- Epoch 17 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.150 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.318 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.141 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.091 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.030 Acc 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1100 Loss 0.048 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.087 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.195 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.254 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.101 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.093 Acc 0.973\n",
      "---------------- Epoch 18 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.190 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.053 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.094 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.359 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.122 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.354 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.057 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.096 Acc 0.972\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.087 Acc 0.973\n",
      "---------------- Epoch 19 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.064 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.268 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.060 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.358 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.185 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.068 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.180 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.093 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.100 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.092 Acc 0.971\n",
      "---------------- Epoch 20 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.006 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.139 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.046 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.161 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.252 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.026 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.094 Acc 0.973\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.085 Acc 0.973\n",
      "---------------- Epoch 21 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.052 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.187 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.136 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.049 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.187 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.331 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.145 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.082 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.040 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.089 Acc 0.974\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.082 Acc 0.975\n",
      "---------------- Epoch 22 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.138 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.074 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.166 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.045 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.113 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.056 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.199 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.080 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.060 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.142 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.084 Acc 0.975\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.078 Acc 0.975\n",
      "---------------- Epoch 23 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.062 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.102 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.122 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.058 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.131 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.202 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.144 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.137 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.505 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.042 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.172 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.091 Acc 0.974\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.083 Acc 0.975\n",
      "---------------- Epoch 24 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.065 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.069 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.168 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.123 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.322 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.280 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.098 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.053 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.041 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.078 Acc 0.977\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.071 Acc 0.979\n",
      "---------------- Epoch 25 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.123 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.047 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.158 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.060 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.120 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.211 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.160 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.012 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.081 Acc 0.977\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.072 Acc 0.978\n",
      "---------------- Epoch 26 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.250 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.208 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.030 Acc 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 700 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.147 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.011 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.082 Acc 0.977\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.073 Acc 0.978\n",
      "---------------- Epoch 27 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.042 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.290 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.066 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.101 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.055 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.008 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.074 Acc 0.978\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.064 Acc 0.980\n",
      "---------------- Epoch 28 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.106 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.103 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.138 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.111 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.069 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.193 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.104 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.034 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.073 Acc 0.979\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.062 Acc 0.981\n",
      "---------------- Epoch 29 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.154 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.047 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.171 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.072 Acc 0.979\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.065 Acc 0.979\n",
      "---------------- Epoch 30 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.110 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.048 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.172 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.040 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.188 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.072 Acc 0.978\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.062 Acc 0.981\n",
      "---------------- Epoch 31 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.104 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.052 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.168 Acc 0.875\n",
      "[  1/1] Training Step 900 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.069 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.248 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.121 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.187 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.070 Acc 0.979\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.061 Acc 0.981\n",
      "---------------- Epoch 32 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.053 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.063 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.201 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.096 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.184 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.012 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.069 Acc 0.980\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.060 Acc 0.982\n",
      "---------------- Epoch 33 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.110 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.091 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.007 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.301 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.307 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.072 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.037 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.067 Acc 0.980\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.058 Acc 0.982\n",
      "---------------- Epoch 34 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.084 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.209 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.052 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.068 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.007 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.116 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.065 Acc 0.981\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.056 Acc 0.984\n",
      "---------------- Epoch 35 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.009 Acc 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 300 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.212 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.146 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.074 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.069 Acc 0.979\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.059 Acc 0.982\n",
      "---------------- Epoch 36 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.035 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.154 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.025 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.063 Acc 0.981\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.055 Acc 0.983\n",
      "---------------- Epoch 37 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.318 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.068 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.039 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.085 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.046 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.065 Acc 0.980\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.054 Acc 0.984\n",
      "---------------- Epoch 38 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.034 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.150 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.150 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.010 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.063 Acc 0.982\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.055 Acc 0.983\n",
      "---------------- Epoch 39 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.278 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.006 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.261 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.001 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.032 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.043 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.021 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.064 Acc 0.982\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.052 Acc 0.984\n",
      "---------------- Epoch 40 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.192 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.220 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.006 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.039 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.070 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.014 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.063 Acc 0.981\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.053 Acc 0.984\n",
      "---------------- Epoch 41 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.103 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.071 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.002 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.179 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.069 Acc 0.979\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.058 Acc 0.982\n",
      "---------------- Epoch 42 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.077 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.045 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.210 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.060 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.034 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.018 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.063 Acc 0.982\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.053 Acc 0.984\n",
      "---------------- Epoch 43 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.182 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.096 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.089 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.042 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.037 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.154 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.084 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.059 Acc 0.983\n",
      "---------------- Testing ----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Testing Step 312 Loss 0.049 Acc 0.984\n",
      "---------------- Epoch 44 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.007 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.258 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.006 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.008 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.058 Acc 0.983\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.048 Acc 0.985\n",
      "---------------- Epoch 45 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.048 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.001 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.066 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.065 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.001 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.007 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.055 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.020 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.062 Acc 0.982\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.051 Acc 0.984\n",
      "---------------- Epoch 46 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.160 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.044 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.043 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.004 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.058 Acc 0.983\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.051 Acc 0.984\n",
      "---------------- Epoch 47 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.037 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.393 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.050 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.060 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.039 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.029 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.038 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.057 Acc 0.984\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.049 Acc 0.984\n",
      "---------------- Epoch 48 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.057 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.003 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.029 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.052 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.179 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.084 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.005 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.066 Acc 0.981\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.055 Acc 0.982\n",
      "---------------- Epoch 49 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.038 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.001 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.004 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.057 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.030 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.132 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.253 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.057 Acc 0.983\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.047 Acc 0.985\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(0, 50):\n",
    "    print(\"---------------- Epoch {} ----------------\".format(i))\n",
    "    trainer = Trainer(loss_function, optimizer, device)\n",
    "    trainer.train_loop(cnn, train_loader, val_loader)\n",
    "    trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10), num='5.4 Training Result')\n",
    "plt.subplot(211)\n",
    "plt.plot(FIG_X[0:len(ACC_TRAIN)], ACC_TRAIN, label=\"Training\")\n",
    "plt.plot(FIG_X[0:len(ACC_TEST)], ACC_TEST, label=\"Testing\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(FIG_X[0:len(LOSS_TRAIN)], LOSS_TRAIN)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (sub2): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (sub4): Sequential(\n",
      "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc3): Sequential(\n",
      "    (0): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"./model\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.047 Acc 0.985\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "testIndex = 0\n",
    "print(testIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 6), num='5.5')\n",
    "TEST_IMAGE, test_image_label = test_data[testIndex]\n",
    "test_image = np.array(TEST_IMAGE, dtype='float')\n",
    "pixels = test_image.reshape((32, 32))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "fig.show()\n",
    "\n",
    "# Test Model\n",
    "model.eval()\n",
    "test = DataLoader(test_data[testIndex])\n",
    "test_x, test_y = test\n",
    "output = model(test_x)\n",
    "output = F.softmax(output, dim=1)\n",
    "output = output.tolist()[0]\n",
    "\n",
    "outputProbLabel = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "plt.bar(outputProbLabel, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
