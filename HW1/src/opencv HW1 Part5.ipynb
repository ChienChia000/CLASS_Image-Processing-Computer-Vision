{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QDialog, QMessageBox, QPushButton\n",
    "from hw1UI import Ui_Dialog\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "OPTIMIZER = \"SGD\"\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 50000\n",
    "def downloadMNIST():\n",
    "    data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data = datasets.MNIST(root=\"./\", train=True,download=True, transform=data_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS)))\n",
    "    \n",
    "    val_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS, 60000)))\n",
    "\n",
    "    test_data = datasets.MNIST(root=\"./\", train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_data, train_loader, test_data, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_loader, test_data, test_loader, val_loader = downloadMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Show 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 14), num='5.1 10 Images and Labels of MNIST')\n",
    "columns = 5\n",
    "rows = 2\n",
    "for i in range(1, columns*rows +1):\n",
    "    randomNum = random.randint(0,60000)\n",
    "    train_image, train_image_label = train_data[randomNum]\n",
    "    train_image = np.array(train_image, dtype='float')\n",
    "    pixels = train_image.reshape((28, 28))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.xlabel(train_image_label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Print Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters:\n",
      "batch size: 32\n",
      "learning rate: 0.001\n",
      "optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperparameters:\")\n",
    "print(\"batch size:\", BATCH_SIZE)\n",
    "print(\"learning rate:\", LEARNING_RATE)\n",
    "print(\"optimizer:\", OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train 1 epoch and show training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS=[]\n",
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "#             print(\"---------------- Epoch {} ----------------\".format(epoch))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        global flag\n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            ###################################\n",
    "            LOSS.append(loss.data.item())\n",
    "            FIG_X.append(flag)\n",
    "            flag=flag+1\n",
    "            ###################################\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "            ####################################\n",
    "            if(state == \"Validate\"):\n",
    "                LOSS_TRAIN.append(loss)\n",
    "                ACC_TRAIN.append(self._accuracy(outs, y))\n",
    "            elif(state == \"Testing\"):\n",
    "                ACC_TEST.append(self._accuracy(outs, y))\n",
    "            ####################################\n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1, self.conv2 = None, None\n",
    "        self.fc1, self.fc2 = None, None\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1152, 200, bias = False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(200, 10, bias = False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 000 Loss 2.304 Acc 0.188\n",
      "[  1/1] Training Step 100 Loss 2.297 Acc 0.281\n",
      "[  1/1] Training Step 200 Loss 2.295 Acc 0.188\n",
      "[  1/1] Training Step 300 Loss 2.290 Acc 0.188\n",
      "[  1/1] Training Step 400 Loss 2.271 Acc 0.500\n",
      "[  1/1] Training Step 500 Loss 2.241 Acc 0.562\n",
      "[  1/1] Training Step 600 Loss 2.170 Acc 0.500\n",
      "[  1/1] Training Step 700 Loss 1.855 Acc 0.656\n",
      "[  1/1] Training Step 800 Loss 1.043 Acc 0.781\n",
      "[  1/1] Training Step 900 Loss 0.580 Acc 0.812\n",
      "[  1/1] Training Step 1000 Loss 0.387 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.460 Acc 0.781\n",
      "[  1/1] Training Step 1200 Loss 0.646 Acc 0.844\n",
      "[  1/1] Training Step 1300 Loss 0.247 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.096 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.338 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.333 Acc 0.902\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.339 Acc 0.898\n"
     ]
    }
   ],
   "source": [
    "LOSS=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "device = \"cpu\"\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(loss_function, optimizer, device)\n",
    "trainer.train_loop(cnn, train_loader, val_loader)\n",
    "trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f758eb2c450>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FIG_X[:len(LOSS)], LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS_TRAIN: []\n",
      "ACC_TRAIN: []\n",
      "ACC_TEST: []\n",
      "X: []\n"
     ]
    }
   ],
   "source": [
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "X=[]\n",
    "flag=0\n",
    "print(\"LOSS_TRAIN:\", LOSS_TRAIN)\n",
    "print(\"ACC_TRAIN:\",ACC_TRAIN)\n",
    "print(\"ACC_TEST:\",ACC_TEST)\n",
    "print(\"X:\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.305 Acc 0.125\n",
      "[  1/1] Training Step 100 Loss 2.302 Acc 0.156\n",
      "[  1/1] Training Step 200 Loss 2.295 Acc 0.156\n",
      "[  1/1] Training Step 300 Loss 2.296 Acc 0.156\n",
      "[  1/1] Training Step 400 Loss 2.291 Acc 0.312\n",
      "[  1/1] Training Step 500 Loss 2.288 Acc 0.312\n",
      "[  1/1] Training Step 600 Loss 2.290 Acc 0.375\n",
      "[  1/1] Training Step 700 Loss 2.294 Acc 0.219\n",
      "[  1/1] Training Step 800 Loss 2.287 Acc 0.281\n",
      "[  1/1] Training Step 900 Loss 2.285 Acc 0.281\n",
      "[  1/1] Training Step 1000 Loss 2.280 Acc 0.406\n",
      "[  1/1] Training Step 1100 Loss 2.273 Acc 0.438\n",
      "[  1/1] Training Step 1200 Loss 2.270 Acc 0.438\n",
      "[  1/1] Training Step 1300 Loss 2.265 Acc 0.500\n",
      "[  1/1] Training Step 1400 Loss 2.258 Acc 0.531\n",
      "[  1/1] Training Step 1500 Loss 2.253 Acc 0.469\n",
      "[  1/1] Validate Step 312 Loss 2.257 Acc 0.530\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.257 Acc 0.523\n",
      "---------------- Epoch 1 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.267 Acc 0.344\n",
      "[  1/1] Training Step 100 Loss 2.244 Acc 0.625\n",
      "[  1/1] Training Step 200 Loss 2.251 Acc 0.531\n",
      "[  1/1] Training Step 300 Loss 2.244 Acc 0.625\n",
      "[  1/1] Training Step 400 Loss 2.211 Acc 0.688\n",
      "[  1/1] Training Step 500 Loss 2.212 Acc 0.594\n",
      "[  1/1] Training Step 600 Loss 2.208 Acc 0.531\n",
      "[  1/1] Training Step 700 Loss 2.215 Acc 0.688\n",
      "[  1/1] Training Step 800 Loss 2.187 Acc 0.750\n",
      "[  1/1] Training Step 900 Loss 2.170 Acc 0.625\n",
      "[  1/1] Training Step 1000 Loss 2.171 Acc 0.750\n",
      "[  1/1] Training Step 1100 Loss 2.145 Acc 0.562\n",
      "[  1/1] Training Step 1200 Loss 2.102 Acc 0.688\n",
      "[  1/1] Training Step 1300 Loss 2.107 Acc 0.625\n",
      "[  1/1] Training Step 1400 Loss 2.128 Acc 0.656\n",
      "[  1/1] Training Step 1500 Loss 2.115 Acc 0.594\n",
      "[  1/1] Validate Step 312 Loss 2.022 Acc 0.687\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.019 Acc 0.677\n",
      "---------------- Epoch 2 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.036 Acc 0.812\n",
      "[  1/1] Training Step 100 Loss 2.004 Acc 0.625\n",
      "[  1/1] Training Step 200 Loss 1.846 Acc 0.719\n",
      "[  1/1] Training Step 300 Loss 1.876 Acc 0.812\n",
      "[  1/1] Training Step 400 Loss 1.881 Acc 0.531\n",
      "[  1/1] Training Step 500 Loss 1.749 Acc 0.656\n",
      "[  1/1] Training Step 600 Loss 1.638 Acc 0.625\n",
      "[  1/1] Training Step 700 Loss 1.586 Acc 0.781\n",
      "[  1/1] Training Step 800 Loss 1.492 Acc 0.688\n",
      "[  1/1] Training Step 900 Loss 1.482 Acc 0.625\n",
      "[  1/1] Training Step 1000 Loss 1.298 Acc 0.750\n",
      "[  1/1] Training Step 1100 Loss 1.193 Acc 0.719\n",
      "[  1/1] Training Step 1200 Loss 1.035 Acc 0.812\n",
      "[  1/1] Training Step 1300 Loss 0.994 Acc 0.719\n",
      "[  1/1] Training Step 1400 Loss 0.730 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.990 Acc 0.750\n",
      "[  1/1] Validate Step 312 Loss 0.807 Acc 0.824\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.810 Acc 0.811\n",
      "---------------- Epoch 3 ----------------\n",
      "[  1/1] Training Step 000 Loss 1.013 Acc 0.750\n",
      "[  1/1] Training Step 100 Loss 0.678 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.984 Acc 0.750\n",
      "[  1/1] Training Step 300 Loss 0.725 Acc 0.719\n",
      "[  1/1] Training Step 400 Loss 0.610 Acc 0.844\n",
      "[  1/1] Training Step 500 Loss 0.610 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.580 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.595 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.566 Acc 0.844\n",
      "[  1/1] Training Step 900 Loss 0.566 Acc 0.781\n",
      "[  1/1] Training Step 1000 Loss 0.505 Acc 0.844\n",
      "[  1/1] Training Step 1100 Loss 0.617 Acc 0.812\n",
      "[  1/1] Training Step 1200 Loss 0.498 Acc 0.844\n",
      "[  1/1] Training Step 1300 Loss 0.517 Acc 0.844\n",
      "[  1/1] Training Step 1400 Loss 0.587 Acc 0.812\n",
      "[  1/1] Training Step 1500 Loss 0.430 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.457 Acc 0.875\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.472 Acc 0.868\n",
      "---------------- Epoch 4 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.706 Acc 0.844\n",
      "[  1/1] Training Step 100 Loss 0.757 Acc 0.781\n",
      "[  1/1] Training Step 200 Loss 0.357 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.349 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.737 Acc 0.719\n",
      "[  1/1] Training Step 500 Loss 0.464 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.416 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.422 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.323 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.436 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.505 Acc 0.844\n",
      "[  1/1] Training Step 1100 Loss 0.678 Acc 0.750\n",
      "[  1/1] Training Step 1200 Loss 0.498 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.497 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.441 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.802 Acc 0.812\n",
      "[  1/1] Validate Step 312 Loss 0.377 Acc 0.894\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.390 Acc 0.891\n",
      "---------------- Epoch 5 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.372 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.383 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.303 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.583 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.212 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.611 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.252 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.645 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.212 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.346 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.618 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.351 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.699 Acc 0.812\n",
      "[  1/1] Training Step 1300 Loss 0.357 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.487 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.529 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.342 Acc 0.904\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.353 Acc 0.901\n",
      "---------------- Epoch 6 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.286 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.393 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.450 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.244 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.248 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.186 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.417 Acc 0.844\n",
      "[  1/1] Training Step 700 Loss 0.700 Acc 0.781\n",
      "[  1/1] Training Step 800 Loss 0.479 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.258 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.272 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.326 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.368 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.479 Acc 0.812\n",
      "[  1/1] Training Step 1500 Loss 0.524 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.318 Acc 0.908\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.328 Acc 0.905\n",
      "---------------- Epoch 7 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.412 Acc 0.844\n",
      "[  1/1] Training Step 100 Loss 0.260 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.344 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.735 Acc 0.719\n",
      "[  1/1] Training Step 400 Loss 0.345 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.530 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.458 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.108 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.435 Acc 0.844\n",
      "[  1/1] Training Step 900 Loss 0.133 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.434 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.336 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.468 Acc 0.844\n",
      "[  1/1] Training Step 1300 Loss 0.150 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.182 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.306 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.300 Acc 0.914\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.310 Acc 0.911\n",
      "---------------- Epoch 8 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.168 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.265 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.315 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.300 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.263 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.438 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.342 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.425 Acc 0.875\n",
      "[  1/1] Training Step 900 Loss 0.197 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.298 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.412 Acc 0.844\n",
      "[  1/1] Training Step 1200 Loss 0.348 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.300 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.256 Acc 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1500 Loss 0.141 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.284 Acc 0.918\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.292 Acc 0.915\n",
      "---------------- Epoch 9 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.198 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.363 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.230 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.153 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.514 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.300 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.276 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.270 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.494 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.397 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.158 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.144 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.137 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.276 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.112 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.270 Acc 0.924\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.278 Acc 0.920\n",
      "---------------- Epoch 10 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.266 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.223 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.187 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.295 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.519 Acc 0.781\n",
      "[  1/1] Training Step 500 Loss 0.161 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.183 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.193 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.187 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.301 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.159 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.283 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.409 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.418 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.139 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.488 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.259 Acc 0.925\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.264 Acc 0.923\n",
      "---------------- Epoch 11 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.223 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.321 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.209 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.263 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.207 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.388 Acc 0.781\n",
      "[  1/1] Training Step 700 Loss 0.548 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.355 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.142 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.395 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.238 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.296 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.170 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.282 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.248 Acc 0.930\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.251 Acc 0.928\n",
      "---------------- Epoch 12 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.171 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.570 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.281 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.261 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.372 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.236 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.185 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.432 Acc 0.844\n",
      "[  1/1] Training Step 900 Loss 0.236 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.222 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.340 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.285 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.206 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.419 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.258 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.236 Acc 0.933\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.240 Acc 0.930\n",
      "---------------- Epoch 13 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.240 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.173 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.183 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.292 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.128 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.190 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.163 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.065 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.163 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.163 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.056 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.118 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.156 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.548 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.175 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.224 Acc 0.936\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.228 Acc 0.934\n",
      "---------------- Epoch 14 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.367 Acc 0.844\n",
      "[  1/1] Training Step 100 Loss 0.588 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.305 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.178 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.224 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.215 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.181 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.272 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.175 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.131 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.226 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.418 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.210 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.217 Acc 0.939\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.218 Acc 0.938\n",
      "---------------- Epoch 15 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.165 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.238 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.301 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.192 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.199 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.201 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.303 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.184 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.269 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.060 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.241 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.154 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.291 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.163 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.475 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.208 Acc 0.940\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.208 Acc 0.938\n",
      "---------------- Epoch 16 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.488 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.344 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.210 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.530 Acc 0.812\n",
      "[  1/1] Training Step 400 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.228 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.242 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.187 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.162 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.407 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.254 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.218 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.238 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.139 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.377 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.361 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.198 Acc 0.945\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.199 Acc 0.943\n",
      "---------------- Epoch 17 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.191 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.290 Acc 0.844\n",
      "[  1/1] Training Step 300 Loss 0.077 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.186 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.161 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.243 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.135 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.161 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.198 Acc 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1100 Loss 0.195 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.121 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.279 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.188 Acc 0.947\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.190 Acc 0.945\n",
      "---------------- Epoch 18 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.152 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.221 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.588 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.088 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.122 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.405 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.131 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.418 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.096 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.194 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.147 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.209 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.329 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.183 Acc 0.949\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.184 Acc 0.947\n",
      "---------------- Epoch 19 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.239 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.243 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.110 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.139 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.274 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.204 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.280 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.292 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.066 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.157 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.172 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.174 Acc 0.951\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.175 Acc 0.948\n",
      "---------------- Epoch 20 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.313 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.522 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.212 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.166 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.406 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.219 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.213 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.228 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.169 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.102 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.252 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.159 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.170 Acc 0.953\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.170 Acc 0.951\n",
      "---------------- Epoch 21 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.241 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.210 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.071 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.500 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.463 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.418 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.091 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.226 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.157 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.188 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.594 Acc 0.844\n",
      "[  1/1] Training Step 1200 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.145 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.242 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.163 Acc 0.953\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.165 Acc 0.952\n",
      "---------------- Epoch 22 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.129 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.299 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.203 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.125 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.070 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.089 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.132 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.244 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.133 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.160 Acc 0.954\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.159 Acc 0.952\n",
      "---------------- Epoch 23 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.192 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.542 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.140 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.125 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.191 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.210 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.135 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.208 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.178 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.279 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.154 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.415 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.234 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.238 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.176 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.153 Acc 0.956\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.154 Acc 0.955\n",
      "---------------- Epoch 24 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.275 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.240 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.182 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.176 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.304 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.073 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.239 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.079 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.273 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.064 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.221 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.136 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.130 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.151 Acc 0.959\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.149 Acc 0.955\n",
      "---------------- Epoch 25 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.124 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.201 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.064 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.400 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.313 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.191 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.201 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.195 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.184 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.212 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.163 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.069 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.150 Acc 0.957\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.152 Acc 0.957\n",
      "---------------- Epoch 26 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.257 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.322 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.226 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.076 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.214 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.045 Acc 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 700 Loss 0.065 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.131 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.119 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.293 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.144 Acc 0.960\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.142 Acc 0.957\n",
      "---------------- Epoch 27 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.137 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.129 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.172 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.120 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.260 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.264 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.192 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.340 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.265 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.130 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.099 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.377 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.114 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.061 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.137 Acc 0.961\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.138 Acc 0.960\n",
      "---------------- Epoch 28 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.169 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.076 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.202 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.169 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.222 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.272 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.264 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.245 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.028 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.135 Acc 0.963\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.133 Acc 0.960\n",
      "---------------- Epoch 29 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.094 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.383 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.042 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.534 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.150 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.108 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.186 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.216 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.045 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.166 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.071 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.132 Acc 0.963\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.132 Acc 0.962\n",
      "---------------- Epoch 30 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.237 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.122 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.119 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.281 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.198 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.121 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.247 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.220 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.109 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.095 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.146 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.175 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.152 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.022 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.131 Acc 0.964\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.130 Acc 0.961\n",
      "---------------- Epoch 31 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.119 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.228 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.164 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.113 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.393 Acc 0.875\n",
      "[  1/1] Training Step 900 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.064 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.048 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.191 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.227 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.127 Acc 0.964\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.127 Acc 0.962\n",
      "---------------- Epoch 32 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.042 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.322 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.127 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.184 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.089 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.181 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.144 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.088 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.132 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.049 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.164 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.067 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.127 Acc 0.964\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.124 Acc 0.963\n",
      "---------------- Epoch 33 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.206 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.266 Acc 0.844\n",
      "[  1/1] Training Step 1400 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.306 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.120 Acc 0.967\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.120 Acc 0.964\n",
      "---------------- Epoch 34 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.111 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.159 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.085 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.092 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.165 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.239 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.159 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.146 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.058 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.327 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.286 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.119 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.117 Acc 0.965\n",
      "---------------- Epoch 35 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.190 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.308 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.093 Acc 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 300 Loss 0.219 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.300 Acc 0.844\n",
      "[  1/1] Training Step 700 Loss 0.125 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.262 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.533 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.082 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.119 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.026 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.117 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Epoch 36 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.208 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.109 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.040 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.096 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.159 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.200 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.201 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.032 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.185 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.139 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.117 Acc 0.967\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.114 Acc 0.966\n",
      "---------------- Epoch 37 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.148 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.197 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.150 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.181 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.239 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.178 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.088 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.259 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.133 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.113 Acc 0.967\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.111 Acc 0.967\n",
      "---------------- Epoch 38 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.180 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.067 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.109 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.497 Acc 0.844\n",
      "[  1/1] Training Step 900 Loss 0.087 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.032 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.112 Acc 0.965\n",
      "---------------- Epoch 39 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.092 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.354 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.146 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.137 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.187 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.098 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.096 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.146 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.101 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.069 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.111 Acc 0.967\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.109 Acc 0.967\n",
      "---------------- Epoch 40 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.283 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.226 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.137 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.109 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.213 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.069 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.286 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.076 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.020 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.108 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.106 Acc 0.968\n",
      "---------------- Epoch 41 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.201 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.151 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.085 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.193 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.076 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.135 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.101 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.091 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.054 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.110 Acc 0.969\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.109 Acc 0.967\n",
      "---------------- Epoch 42 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.352 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.189 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.431 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.188 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.264 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.057 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.256 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.042 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.110 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.108 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.105 Acc 0.968\n",
      "---------------- Epoch 43 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.254 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.086 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.162 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.157 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.231 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.032 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.050 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.104 Acc 0.970\n",
      "---------------- Testing ----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Testing Step 312 Loss 0.102 Acc 0.970\n",
      "---------------- Epoch 44 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.203 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.080 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.163 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.108 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.328 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.023 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.104 Acc 0.970\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.099 Acc 0.971\n",
      "---------------- Epoch 45 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.069 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.140 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.096 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.294 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.113 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.066 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.242 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.124 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.103 Acc 0.970\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.101 Acc 0.969\n",
      "---------------- Epoch 46 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.082 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.040 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.161 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.047 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.077 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.116 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.203 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.057 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.051 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.218 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.101 Acc 0.972\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.098 Acc 0.970\n",
      "---------------- Epoch 47 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.080 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.179 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.130 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.180 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.094 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.243 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.035 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.099 Acc 0.972\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.096 Acc 0.971\n",
      "---------------- Epoch 48 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.048 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.062 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.051 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.048 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.143 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.218 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.112 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.100 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.097 Acc 0.972\n",
      "---------------- Epoch 49 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.038 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.131 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.228 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.216 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.161 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.099 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.095 Acc 0.971\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(0, 50):\n",
    "    print(\"---------------- Epoch {} ----------------\".format(i))\n",
    "    trainer = Trainer(loss_function, optimizer, device)\n",
    "    trainer.train_loop(cnn, train_loader, val_loader)\n",
    "    trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10), num='5.4 Training Result')\n",
    "plt.subplot(211)\n",
    "plt.plot(FIG_X[0:len(ACC_TRAIN)], ACC_TRAIN, label=\"Training\")\n",
    "plt.plot(FIG_X[0:len(ACC_TEST)], ACC_TEST, label=\"Testing\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(FIG_X[0:len(LOSS_TRAIN)], LOSS_TRAIN)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"./model\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.095 Acc 0.971\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "testIndex = 0\n",
    "print(testIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 6), num='5.5')\n",
    "TEST_IMAGE, test_image_label = test_data[testIndex]\n",
    "test_image = np.array(TEST_IMAGE, dtype='float')\n",
    "pixels = test_image.reshape((28, 28))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "fig.show()\n",
    "\n",
    "# Test Model\n",
    "model.eval()\n",
    "test = DataLoader(test_data[testIndex])\n",
    "test_x, test_y = test\n",
    "output = model(test_x)\n",
    "output = F.softmax(output, dim=1)\n",
    "output = output.tolist()[0]\n",
    "\n",
    "outputProbLabel = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "plt.bar(outputProbLabel, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
