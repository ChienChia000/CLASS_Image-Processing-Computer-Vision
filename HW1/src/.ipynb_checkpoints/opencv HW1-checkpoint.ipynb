{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QDialog, QMessageBox, QPushButton\n",
    "from hw1UI import Ui_Dialog\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "OPTIMIZER = \"SGD\"\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 50000\n",
    "def downloadMNIST():\n",
    "    data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data = datasets.MNIST(root=\"./\", train=True,download=True, transform=data_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS)))\n",
    "    \n",
    "    val_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS, 60000)))\n",
    "\n",
    "    test_data = datasets.MNIST(root=\"./\", train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_data, train_loader, test_data, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_loader, test_data, test_loader, val_loader = downloadMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Show 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 14), num='5.1 10 Images and Labels of MNIST')\n",
    "columns = 5\n",
    "rows = 2\n",
    "for i in range(1, columns*rows +1):\n",
    "    randomNum = random.randint(0,60000)\n",
    "    train_image, train_image_label = train_data[randomNum]\n",
    "    train_image = np.array(train_image, dtype='float')\n",
    "    pixels = train_image.reshape((28, 28))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.xlabel(train_image_label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Print Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters:\n",
      "batch size: 32\n",
      "learning rate: 0.001\n",
      "optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperparameters:\")\n",
    "print(\"batch size:\", BATCH_SIZE)\n",
    "print(\"learning rate:\", LEARNING_RATE)\n",
    "print(\"optimizer:\", OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train 1 epoch and show training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS=[]\n",
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "#             print(\"---------------- Epoch {} ----------------\".format(epoch))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        global flag\n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            ###################################\n",
    "            LOSS.append(loss.data.item())\n",
    "            FIG_X.append(flag)\n",
    "            flag=flag+1\n",
    "            ###################################\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "            ####################################\n",
    "            if(state == \"Validate\"):\n",
    "                LOSS_TRAIN.append(loss)\n",
    "                ACC_TRAIN.append(self._accuracy(outs, y))\n",
    "            elif(state == \"Testing\"):\n",
    "                ACC_TEST.append(self._accuracy(outs, y))\n",
    "            ####################################\n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1, self.conv2 = None, None\n",
    "        self.fc1, self.fc2 = None, None\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1152, 200, bias = False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(200, 10, bias = False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 000 Loss 2.299 Acc 0.125\n",
      "[  1/1] Training Step 100 Loss 2.271 Acc 0.406\n",
      "[  1/1] Training Step 200 Loss 2.223 Acc 0.594\n",
      "[  1/1] Training Step 300 Loss 2.016 Acc 0.812\n",
      "[  1/1] Training Step 400 Loss 1.488 Acc 0.656\n",
      "[  1/1] Training Step 500 Loss 0.806 Acc 0.750\n",
      "[  1/1] Training Step 600 Loss 0.395 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.423 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.392 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.430 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.402 Acc 0.812\n",
      "[  1/1] Training Step 1100 Loss 0.365 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.291 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.207 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.352 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.222 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.297 Acc 0.913\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.301 Acc 0.909\n"
     ]
    }
   ],
   "source": [
    "LOSS=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "device = \"cpu\"\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(loss_function, optimizer, device)\n",
    "trainer.train_loop(cnn, train_loader, val_loader)\n",
    "trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9f516d7f90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FIG_X[:len(LOSS)], LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS_TRAIN: []\n",
      "ACC_TRAIN: []\n",
      "ACC_TEST: []\n",
      "X: []\n"
     ]
    }
   ],
   "source": [
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "X=[]\n",
    "flag=0\n",
    "print(\"LOSS_TRAIN:\", LOSS_TRAIN)\n",
    "print(\"ACC_TRAIN:\",ACC_TRAIN)\n",
    "print(\"ACC_TEST:\",ACC_TEST)\n",
    "print(\"X:\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.302 Acc 0.125\n",
      "[  1/1] Training Step 100 Loss 2.301 Acc 0.125\n",
      "[  1/1] Training Step 200 Loss 2.299 Acc 0.156\n",
      "[  1/1] Training Step 300 Loss 2.299 Acc 0.188\n",
      "[  1/1] Training Step 400 Loss 2.303 Acc 0.125\n",
      "[  1/1] Training Step 500 Loss 2.296 Acc 0.156\n",
      "[  1/1] Training Step 600 Loss 2.295 Acc 0.188\n",
      "[  1/1] Training Step 700 Loss 2.294 Acc 0.219\n",
      "[  1/1] Training Step 800 Loss 2.296 Acc 0.188\n",
      "[  1/1] Training Step 900 Loss 2.294 Acc 0.156\n",
      "[  1/1] Training Step 1000 Loss 2.291 Acc 0.219\n",
      "[  1/1] Training Step 1100 Loss 2.288 Acc 0.344\n",
      "[  1/1] Training Step 1200 Loss 2.284 Acc 0.375\n",
      "[  1/1] Training Step 1300 Loss 2.290 Acc 0.219\n",
      "[  1/1] Training Step 1400 Loss 2.284 Acc 0.469\n",
      "[  1/1] Training Step 1500 Loss 2.285 Acc 0.344\n",
      "[  1/1] Validate Step 312 Loss 2.282 Acc 0.394\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.282 Acc 0.383\n",
      "---------------- Epoch 1 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.288 Acc 0.375\n",
      "[  1/1] Training Step 100 Loss 2.277 Acc 0.469\n",
      "[  1/1] Training Step 200 Loss 2.277 Acc 0.344\n",
      "[  1/1] Training Step 300 Loss 2.279 Acc 0.312\n",
      "[  1/1] Training Step 400 Loss 2.279 Acc 0.250\n",
      "[  1/1] Training Step 500 Loss 2.267 Acc 0.438\n",
      "[  1/1] Training Step 600 Loss 2.274 Acc 0.344\n",
      "[  1/1] Training Step 700 Loss 2.275 Acc 0.375\n",
      "[  1/1] Training Step 800 Loss 2.258 Acc 0.562\n",
      "[  1/1] Training Step 900 Loss 2.270 Acc 0.344\n",
      "[  1/1] Training Step 1000 Loss 2.249 Acc 0.562\n",
      "[  1/1] Training Step 1100 Loss 2.226 Acc 0.625\n",
      "[  1/1] Training Step 1200 Loss 2.252 Acc 0.438\n",
      "[  1/1] Training Step 1300 Loss 2.233 Acc 0.469\n",
      "[  1/1] Training Step 1400 Loss 2.246 Acc 0.344\n",
      "[  1/1] Training Step 1500 Loss 2.221 Acc 0.531\n",
      "[  1/1] Validate Step 312 Loss 2.217 Acc 0.518\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.216 Acc 0.514\n",
      "---------------- Epoch 2 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.213 Acc 0.562\n",
      "[  1/1] Training Step 100 Loss 2.191 Acc 0.625\n",
      "[  1/1] Training Step 200 Loss 2.188 Acc 0.594\n",
      "[  1/1] Training Step 300 Loss 2.201 Acc 0.531\n",
      "[  1/1] Training Step 400 Loss 2.171 Acc 0.594\n",
      "[  1/1] Training Step 500 Loss 2.158 Acc 0.594\n",
      "[  1/1] Training Step 600 Loss 2.156 Acc 0.625\n",
      "[  1/1] Training Step 700 Loss 2.074 Acc 0.656\n",
      "[  1/1] Training Step 800 Loss 2.089 Acc 0.688\n",
      "[  1/1] Training Step 900 Loss 2.045 Acc 0.688\n",
      "[  1/1] Training Step 1000 Loss 2.063 Acc 0.469\n",
      "[  1/1] Training Step 1100 Loss 1.970 Acc 0.656\n",
      "[  1/1] Training Step 1200 Loss 1.943 Acc 0.688\n",
      "[  1/1] Training Step 1300 Loss 1.933 Acc 0.688\n",
      "[  1/1] Training Step 1400 Loss 1.860 Acc 0.594\n",
      "[  1/1] Training Step 1500 Loss 1.816 Acc 0.531\n",
      "[  1/1] Validate Step 312 Loss 1.695 Acc 0.692\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 1.688 Acc 0.690\n",
      "---------------- Epoch 3 ----------------\n",
      "[  1/1] Training Step 000 Loss 1.727 Acc 0.656\n",
      "[  1/1] Training Step 100 Loss 1.545 Acc 0.656\n",
      "[  1/1] Training Step 200 Loss 1.540 Acc 0.750\n",
      "[  1/1] Training Step 300 Loss 1.454 Acc 0.781\n",
      "[  1/1] Training Step 400 Loss 1.371 Acc 0.750\n",
      "[  1/1] Training Step 500 Loss 1.161 Acc 0.688\n",
      "[  1/1] Training Step 600 Loss 1.035 Acc 0.750\n",
      "[  1/1] Training Step 700 Loss 1.004 Acc 0.812\n",
      "[  1/1] Training Step 800 Loss 1.135 Acc 0.719\n",
      "[  1/1] Training Step 900 Loss 1.028 Acc 0.781\n",
      "[  1/1] Training Step 1000 Loss 0.971 Acc 0.625\n",
      "[  1/1] Training Step 1100 Loss 0.824 Acc 0.781\n",
      "[  1/1] Training Step 1200 Loss 0.772 Acc 0.812\n",
      "[  1/1] Training Step 1300 Loss 0.606 Acc 0.812\n",
      "[  1/1] Training Step 1400 Loss 0.551 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.596 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.619 Acc 0.843\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.624 Acc 0.836\n",
      "---------------- Epoch 4 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.625 Acc 0.781\n",
      "[  1/1] Training Step 100 Loss 0.532 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.511 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.878 Acc 0.719\n",
      "[  1/1] Training Step 400 Loss 0.428 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.590 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.354 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.447 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.712 Acc 0.781\n",
      "[  1/1] Training Step 900 Loss 0.425 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.614 Acc 0.812\n",
      "[  1/1] Training Step 1100 Loss 0.442 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.706 Acc 0.812\n",
      "[  1/1] Training Step 1300 Loss 0.481 Acc 0.812\n",
      "[  1/1] Training Step 1400 Loss 0.409 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.337 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.429 Acc 0.882\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.441 Acc 0.879\n",
      "---------------- Epoch 5 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.614 Acc 0.812\n",
      "[  1/1] Training Step 100 Loss 0.444 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.279 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.256 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.643 Acc 0.844\n",
      "[  1/1] Training Step 500 Loss 0.259 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.381 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.727 Acc 0.812\n",
      "[  1/1] Training Step 800 Loss 0.233 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.441 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.705 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.541 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.278 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.253 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.589 Acc 0.812\n",
      "[  1/1] Training Step 1500 Loss 0.326 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.374 Acc 0.894\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.384 Acc 0.889\n",
      "---------------- Epoch 6 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.303 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.636 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.505 Acc 0.812\n",
      "[  1/1] Training Step 300 Loss 0.531 Acc 0.812\n",
      "[  1/1] Training Step 400 Loss 0.308 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.710 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.514 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.612 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.640 Acc 0.812\n",
      "[  1/1] Training Step 900 Loss 0.446 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.230 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.161 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.463 Acc 0.844\n",
      "[  1/1] Training Step 1300 Loss 0.529 Acc 0.844\n",
      "[  1/1] Training Step 1400 Loss 0.517 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.300 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.343 Acc 0.902\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.353 Acc 0.898\n",
      "---------------- Epoch 7 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.507 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.571 Acc 0.781\n",
      "[  1/1] Training Step 200 Loss 0.336 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.381 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.334 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.243 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.322 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.434 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.249 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.299 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.638 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.424 Acc 0.844\n",
      "[  1/1] Training Step 1200 Loss 0.280 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.379 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.358 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.519 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.324 Acc 0.910\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.335 Acc 0.903\n",
      "---------------- Epoch 8 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.571 Acc 0.781\n",
      "[  1/1] Training Step 100 Loss 0.125 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.172 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.223 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.263 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.300 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.415 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.441 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.691 Acc 0.812\n",
      "[  1/1] Training Step 900 Loss 0.401 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.548 Acc 0.781\n",
      "[  1/1] Training Step 1100 Loss 0.376 Acc 0.844\n",
      "[  1/1] Training Step 1200 Loss 0.256 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.197 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.246 Acc 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1500 Loss 0.362 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.305 Acc 0.913\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.313 Acc 0.910\n",
      "---------------- Epoch 9 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.710 Acc 0.750\n",
      "[  1/1] Training Step 100 Loss 0.259 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.153 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.362 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.270 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.267 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.444 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.194 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.591 Acc 0.719\n",
      "[  1/1] Training Step 900 Loss 0.352 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.343 Acc 0.844\n",
      "[  1/1] Training Step 1100 Loss 0.386 Acc 0.844\n",
      "[  1/1] Training Step 1200 Loss 0.209 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.296 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.393 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.332 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.291 Acc 0.919\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.296 Acc 0.912\n",
      "---------------- Epoch 10 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.381 Acc 0.812\n",
      "[  1/1] Training Step 100 Loss 0.623 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.274 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.242 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.567 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.334 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.342 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.295 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.524 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.079 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.179 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.220 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.281 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.258 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.426 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.145 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.276 Acc 0.923\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.283 Acc 0.917\n",
      "---------------- Epoch 11 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.105 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.132 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.306 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.063 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.206 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.575 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.304 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.250 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.462 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.256 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.227 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.171 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.239 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.141 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.172 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.270 Acc 0.922\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.272 Acc 0.920\n",
      "---------------- Epoch 12 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.244 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.594 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.127 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.139 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.247 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.101 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.388 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.169 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.656 Acc 0.812\n",
      "[  1/1] Training Step 1000 Loss 0.376 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.688 Acc 0.781\n",
      "[  1/1] Training Step 1200 Loss 0.541 Acc 0.781\n",
      "[  1/1] Training Step 1300 Loss 0.293 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.525 Acc 0.781\n",
      "[  1/1] Training Step 1500 Loss 0.196 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.254 Acc 0.928\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.256 Acc 0.927\n",
      "---------------- Epoch 13 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.351 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.231 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.156 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.259 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.687 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.264 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.154 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.528 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.318 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.155 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.141 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.262 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.447 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.255 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.390 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.246 Acc 0.930\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.247 Acc 0.926\n",
      "---------------- Epoch 14 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.166 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.344 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.129 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.151 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.216 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.368 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.220 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.204 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.190 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.445 Acc 0.812\n",
      "[  1/1] Training Step 1100 Loss 0.157 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.326 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.216 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.084 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.231 Acc 0.935\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.231 Acc 0.933\n",
      "---------------- Epoch 15 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.146 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.266 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.141 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.127 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.228 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.142 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.348 Acc 0.812\n",
      "[  1/1] Training Step 700 Loss 0.140 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.573 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.155 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.169 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.464 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.217 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.097 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.222 Acc 0.938\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.221 Acc 0.936\n",
      "---------------- Epoch 16 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.366 Acc 0.844\n",
      "[  1/1] Training Step 100 Loss 0.233 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.498 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.199 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.332 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.312 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.353 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.082 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.161 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.518 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.204 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.307 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.083 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.078 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.150 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.259 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.212 Acc 0.941\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.210 Acc 0.938\n",
      "---------------- Epoch 17 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.204 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.255 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.243 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.336 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.214 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.099 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.279 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.307 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.233 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.321 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.160 Acc 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1100 Loss 0.274 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.341 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.163 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.138 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.181 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.204 Acc 0.944\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.201 Acc 0.942\n",
      "---------------- Epoch 18 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.081 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.444 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.191 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.176 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.168 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.127 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.250 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.063 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.169 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.199 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.376 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.204 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.163 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.247 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.197 Acc 0.944\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.197 Acc 0.943\n",
      "---------------- Epoch 19 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.413 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.267 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.279 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.263 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.452 Acc 0.875\n",
      "[  1/1] Training Step 500 Loss 0.214 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.331 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.085 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.160 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.190 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.281 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.358 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.047 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.178 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.034 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.189 Acc 0.947\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.186 Acc 0.945\n",
      "---------------- Epoch 20 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.380 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.295 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.096 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.171 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.186 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.066 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.114 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.198 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.331 Acc 0.844\n",
      "[  1/1] Training Step 1100 Loss 0.346 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.129 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.304 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.380 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.068 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.182 Acc 0.948\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.181 Acc 0.947\n",
      "---------------- Epoch 21 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.175 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.135 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.080 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.170 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.128 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.497 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.161 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.185 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.191 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.381 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.246 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.198 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.269 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.175 Acc 0.951\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.173 Acc 0.949\n",
      "---------------- Epoch 22 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.318 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.185 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.066 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.283 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.191 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.135 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.175 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.315 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.097 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.171 Acc 0.953\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.170 Acc 0.952\n",
      "---------------- Epoch 23 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.302 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.073 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.083 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.219 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.243 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.250 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.166 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.198 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.269 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.182 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.110 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.164 Acc 0.955\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.163 Acc 0.953\n",
      "---------------- Epoch 24 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.148 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.194 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.247 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.281 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.267 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.188 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.481 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.193 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.251 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.192 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.101 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.160 Acc 0.955\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.160 Acc 0.953\n",
      "---------------- Epoch 25 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.223 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.369 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.095 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.281 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.132 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.106 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.246 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.230 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.159 Acc 0.955\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.160 Acc 0.953\n",
      "---------------- Epoch 26 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.293 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.090 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.111 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.161 Acc 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 700 Loss 0.292 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.156 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.082 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.118 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.121 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.139 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.229 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.108 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.151 Acc 0.957\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.151 Acc 0.955\n",
      "---------------- Epoch 27 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.065 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.083 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.129 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.140 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.263 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.286 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.113 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.373 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.062 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.381 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.320 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.152 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.148 Acc 0.959\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.149 Acc 0.957\n",
      "---------------- Epoch 28 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.186 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.262 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.284 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.132 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.171 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.325 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.102 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.202 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.103 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.103 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.143 Acc 0.958\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.143 Acc 0.958\n",
      "---------------- Epoch 29 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.284 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.321 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.203 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.188 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.167 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.114 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.311 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.271 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.077 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.144 Acc 0.961\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.142 Acc 0.957\n",
      "---------------- Epoch 30 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.377 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.440 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.183 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.205 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.176 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.087 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.281 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.078 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.111 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.099 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.137 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.136 Acc 0.960\n",
      "---------------- Epoch 31 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.420 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.197 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.120 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.267 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.137 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.042 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.162 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.049 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.241 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.148 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.135 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.133 Acc 0.960\n",
      "---------------- Epoch 32 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.143 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.117 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.401 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.213 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.167 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.311 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.115 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.369 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.146 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.112 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.049 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.130 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.131 Acc 0.963\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.130 Acc 0.961\n",
      "---------------- Epoch 33 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.228 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.197 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.211 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.250 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.055 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.082 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.157 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.060 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.148 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.130 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.128 Acc 0.962\n",
      "---------------- Epoch 34 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.150 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.519 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.181 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.206 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.424 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.408 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.160 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.170 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.124 Acc 0.964\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.125 Acc 0.963\n",
      "---------------- Epoch 35 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.121 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.187 Acc 0.906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 300 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.332 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.145 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.353 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.268 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.086 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.181 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.127 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.125 Acc 0.964\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.123 Acc 0.963\n",
      "---------------- Epoch 36 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.062 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.074 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.139 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.232 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.227 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.225 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.113 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.177 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.135 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.121 Acc 0.965\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.120 Acc 0.964\n",
      "---------------- Epoch 37 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.081 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.297 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.091 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.132 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.318 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.049 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.132 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.250 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.119 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.118 Acc 0.964\n",
      "---------------- Epoch 38 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.171 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.118 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.033 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.166 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.309 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.116 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.115 Acc 0.965\n",
      "---------------- Epoch 39 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.069 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.119 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.118 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.059 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.062 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.129 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.070 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.139 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.223 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.236 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.113 Acc 0.965\n",
      "---------------- Epoch 40 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.426 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.156 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.241 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.200 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.049 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.058 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.121 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.360 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.317 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.095 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.119 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.117 Acc 0.964\n",
      "---------------- Epoch 41 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.051 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.076 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.103 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.335 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.106 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.184 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.097 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.179 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.185 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.115 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Epoch 42 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.656 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.387 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.344 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.134 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.053 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.139 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.145 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.128 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.293 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.325 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.106 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.128 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.109 Acc 0.969\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.109 Acc 0.967\n",
      "---------------- Epoch 43 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.282 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.176 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.138 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.076 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.090 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.183 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.197 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.441 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.219 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.139 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.018 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.109 Acc 0.969\n",
      "---------------- Testing ----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Testing Step 312 Loss 0.107 Acc 0.968\n",
      "---------------- Epoch 44 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.111 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.099 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.093 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.066 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.109 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.192 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.113 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.111 Acc 0.966\n",
      "---------------- Epoch 45 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.312 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.079 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.052 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.071 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.101 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.013 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.209 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.062 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.227 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.151 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.093 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.106 Acc 0.969\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.105 Acc 0.968\n",
      "---------------- Epoch 46 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.060 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.187 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.079 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.071 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.145 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.146 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.233 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.032 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.067 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.105 Acc 0.969\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.103 Acc 0.970\n",
      "---------------- Epoch 47 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.272 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.075 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.078 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.216 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.090 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.183 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.138 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.131 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.088 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.105 Acc 0.970\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.102 Acc 0.969\n",
      "---------------- Epoch 48 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.091 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.191 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.043 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.260 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.055 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.031 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.368 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.101 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.102 Acc 0.970\n",
      "---------------- Epoch 49 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.018 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.131 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.068 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.091 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.171 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.226 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.096 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.140 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.104 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.100 Acc 0.970\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.100 Acc 0.971\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(0, 50):\n",
    "    print(\"---------------- Epoch {} ----------------\".format(i))\n",
    "    trainer = Trainer(loss_function, optimizer, device)\n",
    "    trainer.train_loop(cnn, train_loader, val_loader)\n",
    "    trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAAJOCAYAAABV4NRRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZhdV3nn++97Ts2jhirNo215kGXLRsKYKRjSDiZhCg00BgIEDE9C6IQQ0tfkdrhppwPp201CrttOQtwkbhpMaCcNdELaIQk00BCwjCXLGmwN1lAaS0PN0xnW/eMc2YUsWSWpSqd06vt5nv3s4aza+y1tu/TTqrXXjpQSkiRJUrXKVLoASZIkaSoZeCVJklTVDLySJEmqagZeSZIkVTUDryRJkqqagVeSJElVzcArSZKkqmbglXRJRcS3I+JkRNRXuhZJ0sxg4JV0yUTECuCVQALeeAmvW3OpriVJmn4MvJIupfcA/wz8BfDeUwcjojEiPhMReyOiNyK+FxGN5c9eERHfj4ieiNgfEe8rH/92RNw17hzvi4jvjdtPEfErEbED2FE+9kflc/RFxGMR8cpx7bMR8VsRsSsi+sufL42I+yLiM+O/iYj4nxHx0an4A5IkTT4Dr6RL6T3AF8vLayNifvn4fwLWAS8D5gD/BihGxDLg74B7gU7gJmDjeVzvzcBLgNXl/UfL55gDfAn47xHRUP7sY8CdwM8CbcD7gSHgQeDOiMgAREQH8NPAQ+fzjUuSKsfAK+mSiIhXAMuBr6SUHgN2Ae8sB8n3A7+WUjqQUiqklL6fUhoF3gX8Q0rpoZRSLqV0PKV0PoH30ymlEymlYYCU0n8rnyOfUvoMUA9cU257F/BvU0pPpZJN5bY/AnophVyAdwDfTikducg/EknSJWLglXSpvBf4+5TSsfL+l8rHOoAGSgH4dEvPcnyi9o/fiYjfiIht5WETPUB7+frnutaDwLvL2+8GvnARNUmSLjEf5JA05crjcd8OZCPicPlwPTALWAiMAFcCm0770v3ALWc57SDQNG5/wRnapHE1vBL4vyj11G5JKRUj4iQQ4651JfDkGc7z34AnI2ItcB3w1bPUJEmahuzhlXQpvBkoUBpLe1N5uQ74LqVxvZ8H/iAiFpUfHntpedqyLwL/IiLeHhE1ETE3Im4qn3Mj8JaIaIqIq4APnKOGViAPdAM1EfFJSmN1T3kA+N2IWBUlN0bEXICUUhel8b9fAP7q1BAJSdLlwcAr6VJ4L/DnKaV9KaXDpxbgP1Map3s3sJlSqDwB/Acgk1LaR+khst8oH98IrC2f8w+BMeAIpSEHXzxHDY9QegDuaWAvpV7l8UMe/gD4CvD3QB/wX4DGcZ8/CNyAwxkk6bITKaVzt5KkGS4iforS0IYVKaVipeuRJE2cPbySdA4RUQv8GvCAYVeSLj/nDLwR8fmIOBoRZ3qQg/JYt/8vInZGxBMR8aLJL1OSKiMirgN6KD1c99kKlyNJugAT6eH9C+COF/j8dcCq8vIh4I8vvixJmh5SSttSSs0ppZellPoqXY8k6fydM/CmlL5D6WGRs3kT8F/LE7X/MzArIhZOVoGSJEnSxZiMeXgX85NPOneVjx06vWFEfIhSLzDNzc3rrr322km4vCRJ0tR67LHHjqWUOi/h9ebV1NQ8AKzBZ67OpQg8mc/n71q3bt3RMzWYjMAbZzh2xqkfUkqfAz4HsH79+rRhw4ZJuLwkSdLUioi9l/J6NTU1DyxYsOC6zs7Ok5lMxim1XkCxWIzu7u7Vhw8ffgB445naTMa/GLoovZLzlCXAwUk4ryRJ0ky1prOzs8+we26ZTCZ1dnb2UuoNP3ObSbjO14H3lGdruBXoTSk9bziDJEmSJixj2J248p/VWXPtOYc0RMRDwG1AR0R0Af8PUAuQUvoT4BuU3oS0ExgCfvGiq5YkSZImyTkDb0rpznN8noBfmbSKJEmSVFGHDx/O3nbbbdcAHDt2rDaTyaQ5c+bkATZu3LitoaHhnL3Pb33rW1f89m//9qG1a9eOnq3Npz/96c5Zs2YVfvmXf/mFZgS7aJPx0JokSZKqyIIFCwrbt2/fCvCxj31sUUtLS+Gee+45Mr5NsVgkpUQ2mz3jOR5++OE957rOJz7xie7JqPdcnOZCkiRJE/Lkk0/Wr1q16vp3vvOdy66//vrV+/btq73zzjuXr1mz5rqrrrrq+o9//OPPvoth3bp113z/+99vzOVytLa23vThD3948TXXXLP6pptuuvbAgQM1AL/6q7+66J577pl3qv2HP/zhxTfccMN1K1asWPPNb36zGaCvry/z2te+9sprrrlm9Rve8IaVa9asue773/9+4/nUbQ+vJEnSNPabD29a+vTh/qbJPOfVC1qH/uNb1+4/d8vn27VrV8MDDzzwzKte9ap9AJ/97Ge75s+fX8jlctx6663XPPbYYyfXrVs3Mv5rBgYGsrfddlv//ffff+Cuu+5act9993V86lOfOnz6uVNKbN68edsXv/jF9nvuuWfR7bffvuP3f//3582bNy/3yCOP7PrBD37Q+IpXvGL1+dZsD68kSZImbOnSpaOvetWrhk7tf/7zn5+zevXq666//vrVu3fvbnjiiSee1/va0NBQfPvb394HsG7duqE9e/bUnencb3vb23oAXvaylw11dXXVAfzgBz9oede73nUC4KUvfenwlVdeOXy+NdvDK0mSLpmUErlCYjRfYCRXfHY9kiswmi8y+uw6R32mSH0G6msS9ZlEXRbqs0FdprRfm0nUZRJ1TW1Ec0elv7Upc6E9sVOlsbGxeGp78+bN9X/6p386f8OGDds6OjoKb3rTm1YODw8/76VkNTU1zz7kls1mU6FQONOLy2hoaCie3qY0P8LFMfBKknSJpZR+IuS90HosX6SQEsViopASqZCHwhjkx4jCKBTGiEIOijlSXQs0d1Jb30BjbZaG2iwNtZmf2G6ozZISDI7lGRzNMzBaKK/zDIzkGRoZIQ12kx08Qt3wcRoLvTQV+mksDpTW5WX8sYbCAMXIMBoNjEQDIzQwTD2DNDCU6hlM9QwU6+gv1pMrBk0M0xQjNDNKEyO0xDBNjNLOCM0xTDOj1Eduwn+e/zz3zdz6rx+cwjums+np6ck2NzcXZs+eXdi7d2/td77znbbXvva1vZN5jZe+9KUDDz300Ow77rhj4Ec/+lHj7t27z2v8Lhh4JUmXgWIxMVYokisUKRRLPYT5YpF8IZEvJgrFYulYIZErFsnli8+2H8sXGc2XPh/LF8nlCxTGRkhjA2RSnppshpqaGmqy2dJSU16Xj9dma8jW1JCPGgrFRDElCkXGbT+3LhQTg6N5+kby9A3n6B3O0TeSo284T//wKIWRPhjuJTPWSxuDtDFIewzSfoZ1Z5Q+b41h6slRS546cmTj3L1dPamZ46mNY7TTndrZndo4lto5RjvHUxtFMsyLHubHSTo5yfzoYVmcZF70MJfes15jkEb6o4V+mumJFvYzj/64goFsMzWRaI4xmmOEphilkVHmpBEW0UN9cYT6zDB1xREyqUiupol8tol8TROF2maKNfNIdc2k2mbG6lvI1TVDbROFqCGfgnzKkC8G+RTkEuRShlwxyKUgVwxmLbt+sv+T0wS9/OUvH1q1atXI1Vdfff2yZctG161bNzDZ17j77ruPvu1tb1t59dVXr77hhhuGrrrqquE5c+YUzuccMRndxBdi/fr1acOGDRW5tiTNZMViKvfuFRgYzTE4WiCCZ3sB68f1CNZmz/yoR75QpG8kT8/QGL0DAwz2nmC47zijAyfJDZ4kP9xHsZgoRoYiWYoERTIUyVAgQ4rydspAYYw0NkTkBon8ENncMNnCIDX5YWqLw9QWhqlPI9SRH3eeoMBz5yiMO3eRoIlRmmOYlnLvYfP4NcPUxnn9XQnAWMoyTD1D5V7LoXHbgzQwnOoZpp5GRmmLIWZnhpiVGS6FVgZpTENkOPvfucXIkq9ro1DXTqG+ndQwCxpmQX0r1NQTNfWldbYOaurI1NRBTT2Zmgaipo7I1lAY7qPQd4TiQDcMHiUGu8kOdVMzcpzased3uiWCfONcCk3zSa0LyLQuoKZ9Edn2hdC6AFrmQ+PsUh0N7ZCduf1kEfFYSmn9pbrepk2b9qxdu/bYpbredJbL5cjlctHU1JQ2b95cf8cdd1y9Z8+ezbW1tT/RbtOmTR1r165dcaZzzNz/ciWpwkZyBY4PjnF8YJTjg2MMjuYZyRUZzhUYzRUYHiswki8wPFZkJF9gJFdacvkiQaIUVxi3nSCV9oNESkVGR8cYHR1hbHSEsbFRxsZGyefGyr2FeWooUBt5GhijkTGaYoQGxmhilMYYpTnGaMmM0ZzJ0ZIZpTGN0FgcoLk4SFsMspAhroixKfnzKZAll2kgV99IPttIMVNHJhKRytE5FQiKREpkKBCpSKQCQaJY00ixtoViXQvUzSfVtRL1LVDfSr6hhWJDG5mGVsjUUiwWKRQLFAoFCoUixWKBYqFAvlgkFUvHUiFHTWGYbH6YusIQjbkh5hWGyOaGyOSHyeRPkMkNEvlhqGsm09BONM6GhhWloHjWZRY0zoLG2WTqWqiLMw5rnLDaF/owPwaD3aUlFaB1IdHcSW229oW/Tqqw3t7e7Kte9aqr8/l8pJS49957954eds/FwCtJ4xSKiZ6hMU4MPrccH/zJ/RODY4zli9TXZqivydBYk2jNjNGSzdOcGaMlk6cpRmnK5KhNeXpHEydGgxMjiWMj0D0ER4eK9I5lGKOGMWrIUUMbQ3RGD/Oih3n00Bk9zM/0sCDTx7wo7c9NJ2nmvB9Qfk4GqJ9481ymnlw0MJapZzQaGMs0MlbbTqFuKb0NbfQ1ziLbOIua5tk0tMymsW0OjW1zqGlsL50gFaFYKAWsYrG0/oljBcjWQV0T1DZDXXmpbSJbU082goYL/241Xk0dtC8uLdJlpKOjo7Bly5ZtF3MOA6+kaenUAzqFYnmMZqG0ny+WxnDmC4mUoJhSeSk9CFQsH0vj1rlikd7hHL1DOXqGxugZztEzlKNvaISxgZMUhnpIwydhpIfMWD8tDNHGEK1xaj3MNZR+PT0rO0w7QzQwQn0apS6NkqV47m/odBmYUJKra4WWeeVfL18DLQtKPYNR6tt9bs1p++V1tg6yteWlrrRkap7bPvVZTQPUNpWDZxPUNkJNI7WZDLXApE4AKkmXmIFX0qRIKTGcK9AzVAqTPcNjpYB5KlyO5BgeGWNsdIji6ADFkUGKY4MwNkjkBsnkhsnkh8jmh4mU59TIz0x5yZKePZaNUyM507PLT+6XfuV/aruGAm0xRCeDXHXqwaDMIG0MPf8bGfdbskRQrGuF+jaisY1MQzs0LIX6tmd7IalthNoGqGksb5eWQraBXNRRyNTRlC0SxVzpV8qFUSjkIF96uv7ZJT8GDW2lcNuyAFrnl8ZP1jVfupsoSVXKwCvpnPpGchzsGeZQzwgHe4d/Ynuwv4/scDf1I8eYVTxJZ/SWFnroiF6ujV46o4fZ9NMco+e+2AR/KhXJQAQpMlB+CIooxVyivE/580wNxfo2onEWmabF1DTNJtNYHjvZcPq6vRRoG9qIulaymQt7P0+2vEiSKs/AK80Aw2MF9p8c4kjfCMNjZ57vc3Tc/nCuQG/PSUZPHiQGDtOaO868OMn88rRFr4yTLMz2Mo+TNKbyeNJxP00SQa5hDsWmedCymJq2F5Ft6YT6lvKvzZ8bp0ldy3O/Rq9rKfWQZmshspDJlNdZiJ/czlzkwz2SpJnDwCtVgWIxcbR/lH0nhp5d9p8Yout4P30njlAcPM7c6GMWA7RF6Vf5p9ZzYui5uUBjiPbyfiPl3tgAyi+ALGYbKLYsINu2gGi7FloXln8FPx+a5z27HU1zqZvB0xdJ0uXu8OHD2dtuu+0agGPHjtVmMpk0Z86cPMDGjRu3NTQ0TGhe289+9rNz3/KWt/QuW7YsD/DWt751xW//9m8fWrt27QR+5Td5/BtJqoBcociJwTG6+0vTUR3rH+XYwHPb3f0j5AePU1sYpq44Sm0apa44Ql0aoy6NUJvGqEujzz40VZPro73Yy9zoZ3n0cTP9dGT6aWWwNO/nGZ7KT5Eh1beTGtqJhnaicQExfqqk5s5SoG1d8OySqW+zZ1WSZoAFCxYUtm/fvhXgYx/72KKWlpbCPffcc+R8z/OFL3yh45Zbbhk6FXgffvjhPZNc6oQYeKUp0DeSo+vEMF0nh+g6OVxeStuHeocZHBpiYRxnURxncRxjEaX1msxxlmaPMz8do56Jz21azGQZbWin2DiXTEsndW2rybZ0QFMHNM2F5rnl7TnPjlWNuhbC8CpJOk/33nvv3M997nPzcrlcrF+/fuDBBx/cVywWedvb3rZy69atjSmleO9739s9f/783LZt25re+c53XtnQ0FDcuHHjtpe//OVX33vvvfte/OIXD8+ZM+emX/iFX+j+x3/8x/bGxsbi3/7t3+5cvHhxfvPmzfXvete7VqaU4jWveU3v5z//+Xn9/f0bL6ZmA690nkZyBY70jXC4d4TD49bdx08ycOIwY31HaBg7wdzoYy59zI0+1mb7eV3tAPMy/czJnKS14fjzzltsmU+0LyXab4FZS6FtcfkNSw3PPf1fU54RoLbpuWmkahvI1DbTeIEPV0mSprmv/spSjm6d3NkB560e4s337T/fL3v00Ucbvva1r8368Y9/vK22tpY777xz+Z/92Z/Nufrqq0dPnDhR8/TTT28FOHbsWLajo6PwJ3/yJ/PuvffefS972cueN4H4wMBA9rbbbuu///77D9x1111L7rvvvo5PfepThz/84Q8v++hHP3rk/e9//8lPfepTnZPx7Rp4pdMUiol9J4Z46nAfO44McKhniMGThyj2HqJm4CDNY90sjOMsiJPM5wRr4gQL4iTNMfLcSeqe20y1TdDcQTR3QtOVpXGu7UtLobZ9SWlpW0ym5jzeBiBJUgX83d/9XdsTTzzRfMMNN6wGGBkZySxZsmTszW9+c+/u3bsbfvEXf3Hp61//+t6f//mf7zvXuRoaGopvf/vb+wDWrVs39N3vfrcFYNOmTc3vfe97dwB84AMfOPHpT3/6ot+WYuDVjHZ8YJTth/vZfrifpw738dThfo4d2c+LC0/wyuxm3hTbWZQ5QQ2F576oFopRw1hjJ6l1ETWzXkztrMWleVObO0tDB5o7obmjFHSdR1WSdDEuoCd2qqSUuPPOO4/90R/90cHTP9uyZcuWv/qrv2q/99575z388MOzH3roob0vdK6amppnH3zLZrOpUChM2Tg7A6+qUkqJvuE83QPlh8EGxjhW3j42MEbXySG2Hern2MAo9YyxPvMUP1O/lV+p2czy7G7IQr5+NrHylWQ7roK2RaWldWGpN7a5kwaHEEiSZpjXve51/W9/+9uvvPvuu48uXLgwf/jw4Wx/f3+2ubm52NjYWHz/+99/8qqrrhr98Ic/vBygubm52NfXd17Tkt94442DX/jCF2a9733v6/nzP//zOZNRt4FXl7VjA6NsPtDL1r1H6NvzOAMDvRwbguMjieFChhw15SVLLtVQiBpamhq5vmWAT87dys1tj7Oo9zGyhVGIWlh8K1z5brjyNdQsWFuaB1aSJAFwyy23DN99990HX/3qV19dLBapra1N999//95sNssHP/jBFSklIoLf+73f6wJ4z3vec+yXfumXVpx6aG0i17jvvvv2vfvd777iM5/5zMLbb7+9t7W1tXDur3phkdKEplGbdOvXr08bNmyoyLV1eeoZGmPzgV6e2N/DwT1PU3NoAyuGt3BzZgerYy91cQH/P3RcDVe+prQsf3npxQiSJJ0mIh5LKa2/VNfbtGnTnrVr1x67VNebTvr6+jItLS3FTCbD/fffP+drX/va7EceeWTXub5u06ZNHWvXrl1xps/s4dWUyxeK7D85zM6jA+zqHmDn0dLSO5yjJhPUZjPUZk+tM9Rkg7px25EbIR38MYsHnuTmzE7eltnBvOgBIFfXwHDnWtLKN8DyW0rTbhXGoJArL+XtYu4njze0wcpXlR4ckyRJ08Z3vvOd5o9//ONLi8Ui7e3thQcffPCZiz2ngVeTZixfZMfR/mcD7alwu+fYEGOF4rPt5rXWc2VnC0vnNFEoFKgb66Ft7AizckeYNXSU2fmjzCl001HopqPYTUc6QZYi1MJw63KyS2+HFS+BpbdQO+96an2jlyRJVeP1r399/+tf//qtk3lOk4IuSO9wjm2H+th6sI8tB/vYeqiPnUf7yRVKQ2QyAcvnNnNlZzOvvnYeV3U0cV3jSVbmd9N84nE49AR074S+A5Af+cmTZ+tLD4i1L4H2m0pTeC1+ESx5MY3NHRX4biVJuuSKxWIxMplMZcaeXmaKxWIAxbN9buDVCxrJFeg6OcTu7kG2Hepn66Fethzso+vkc/NHd7TUc/2iNm67ppPrFrZxbUcdK4r7qOveAoc3l8Lt40/CWH/pCyILndfAghvgmteVAm374tKLFtqXlqbz8g1gkqSZ7cnu7u7VnZ2dvYbeF1YsFqO7u7sdePJsbQy8M1xKie7+UfadGPqJZX95faRv9Nm2EXDN3Bp+en6OtdcMc03zEMvqemkdOw79h+HoYdh5CE7sgmK+9EV1LTB/Dax9RyngLrgB5q0uvS1MkiSdUT6fv+vw4cMPHD58eA3glEEvrAg8mc/n7zpbAwPvDJNSYsvBPr791FG+9VQ3Ww72MpJ77jcAEbCgrYFls+t5+9I+bo6nWDWyhY6Bp2gYOUIM9MLAaSfN1ELrgtLSsQque3053N4Is1c6tZckSedp3bp1R4E3VrqOamHgnQEGRvN8b8excsg9+myv7Y1L2nnXS5azfG4TK1qLXDX2FJ09G6k98CPo2gCHy28FbJ4Hi9fBrNugZX7p5Qut5XXLgtLMCA5BkCRJ09SEAm9E3AH8EZAFHkgp/f5pny8HPg90AieAd6eUuia5Vp2H3d0DfOupbr61/Sg/fOY4uUKitb6GV17dwWtWzeHVnb3M7XsKur4Km34IR56EVASiNOTghrfC0peUltkrDLSSJOmydc7AGxFZ4D7gdqALeDQivp5SGj9dxH8C/mtK6cGIeA3waeAXpqJgndngaJ4f7DrOd3Z0852nu9lzfAiA6ztr+a21Q/xU6yFW5HaSPbIZ/n7LczMj1DbDkvXwU78JS2+BJS+GhvYKfieSJEmTayI9vLcAO1NKuwEi4svAm4DxgXc18Ovl7W8BX53MIvV8xWJi66E+/vfTpYD7430nyRUSV9Se5IOdW7n1ir0sHd1J3YkdsLX8BrKG9tK42hffVVovvBHmrgLnsZUkSVVsIklnMbB/3H4X8JLT2mwC/iWlYQ8/D7RGxNyU0vHxjSLiQ8CHAJYtW3ahNc9YR/tH+N6OY3zn6W6+t/MYxwbGAHj1vCH+9IqNvHjou7Qe31QaVNKyABauhevf8Fy4nbXcoQmSJGnGmUjgPVNCOn0+uI8D/zki3gd8BzgA5J/3RSl9DvgcwPr1651TboI27DnB/d/exT9tPwrA3OY6fn75CG+u28A1J/6J2qNPQB+w6Gb4F78D170R5l5ZyZIlSZKmjYkE3i5g6bj9JcDB8Q1SSgeBtwBERAvwL1NKvZNV5EyUUuLbT3fzx9/axY/2nGB2Uy2/c2uW12V/xLyu/0Xs3lJquHg93P67sPqNpYfLJEmS9BMmEngfBVZFxEpKPbfvAN45vkFEdAAnUkpF4BOUZmzQBSgUE9/YfIg//vYuth7q48q2xBdv2satPf+T7MZNpUZLb4XXfhquewPMWvrCJ5QkSZrhzhl4U0r5iPgI8Ailack+n1LaEhH3ABtSSl8HbgM+HRGJ0pCGX5nCmqvSaL7AX//4AH/6v3ex5/ggPzvnAP951T+z8vAjxPbB0lRhr/00XP9maFtU6XIlSZIuG5FSZYbSrl+/Pm3YsKEi155OBkfzfOmH+3jge7sZ7jvOh+f8mHfW/BNtfU9DbROseQu86H2lqcN84EySpIqIiMdSSusrXYcujPNRVdBIrsDb/vj7NB95lP846//w8ubvkR0ahYU3wU/9Iax5KzS0VbpMSZKky5qBt4L+4O+f4teP/w631z8GxTa4+d2w7r2l6cQkSZI0KQy8FfKDXcc5/v0Hub32MfipfwOv+CjUNVe6LEmSpKpj4K2AvpEcv/uX/5uHar9IYclLyN72CchkKl2WJElSVTJlVcDvfG0LHxz+PK2ZEbJv/CPDriRJ0hQyaV1if/vEIY5u+l/8fPa7ZF7x6zDvukqXJEmSVNUc0nAJHe4d4Z6/3sBXG/6cNOsq4pW/UemSJEmSqp6B9xJJKfGbD2/iA8X/zkIOwxv+BmobKl2WJElS1XNIwyXyX3+wl+6dP+au7N/ATe+Gla+sdEmSJEkzgj28l8DOowP8/je28Detf0HUzIaf+d1KlyRJkjRjGHin2Fi+yK//5UbeW/sPXDm2HV7/ADTNqXRZkiRJM4ZDGqbYvf+0g+4Du/l49stw5WvghrdWuiRJkqQZxR7eKfTY3pPc962dfK3zK9QMJ/i5P4CISpclSZI0o9jDO0UGR/N87Csb+Vctm7ih/7vw6k/AnJWVLkuSJGnGMfBOkX//t1s5eeIY/67mL2D+DXDrhytdkiRJ0ozkkIYpsP/EEA/9aD8PL/s76o4ehXc/BNnaSpclSZI0I9nDOwWePNDLi+Jp1h39a3jJL8HidZUuSZIkacYy8E6B7YdO8una/0JqXQiv+b8rXY4kSdKM5pCGKTC058dck9kPP/3HUN9a6XIkSZJmNHt4p0DNsa2ljWW3VrYQSZIkGXgn28BongVDTzOWbYZZKypdjiRJ0oxn4J1kTx3uZ3VmL4Ozr4WMf7ySJEmVZiKbZNsP9XBt7Kd20Y2VLkWSJEn40NqkO7L3KVpjmLT85kqXIkmSJOzhnXTFQ08AEAtuqHAlkiRJAgPvpEop0XpyG0UyMO+6SpcjSZIkDLyTquvkMFcU99DXshJqGytdjiRJkjDwTqrt5RkaCvPWVLoUSZIklRl4J9Ez+/azOI7T4gNrkiRJ08aEAm9E3BERT6oW54cAACAASURBVEXEzoi4+wyfL4uIb0XE4xHxRET87OSXOv0N7d8EQP1ipySTJEmaLs4ZeCMiC9wHvA5YDdwZEatPa/Zvga+klG4G3gHcP9mFXg7qjj1Z2nCGBkmSpGljIj28twA7U0q7U0pjwJeBN53WJgFt5e124ODklXh5GB4rMH9oBwO1HdAyr9LlSJIkqWwigXcxsH/cflf52Hi/A7w7IrqAbwD/+kwniogPRcSGiNjQ3d19AeVOXzuO9nNd7GN4jtORSZIkTScTCbxxhmPptP07gb9IKS0Bfhb4QkQ879wppc+llNanlNZ3dnaef7XT2NMHTnBVdFG7eG2lS5EkSdI4Ewm8XcDScftLeP6QhQ8AXwFIKf0AaAA6JqPAy8WxPZuoiwJtK19U6VIkSZI0zkQC76PAqohYGRF1lB5K+/ppbfYBPw0QEddRCrzVNWbhHNKhzQBkfGBNkiRpWjln4E0p5YGPAI8A2yjNxrAlIu6JiDeWm/0G8MGI2AQ8BLwvpXT6sIeqlVKitWc7Y1EPc6+sdDmSJEkap2YijVJK36D0MNr4Y58ct70VePnklnb5ONI3ypWFZ+idczWdmWyly5EkSdI4vmltEmw71MvqzB6K832lsCRJ0nRj4J0EXXt20B5DtPlKYUmSpGnHwDsJRvZvBKBxmYFXkiRpujHwToL6Y1soEjDv9DcuS5IkqdIMvBdpNF9g3vBOehqWQH1LpcuRJEnSaQy8F2nX0UGuYw/Dc6+vdCmSJEk6AwPvRdq5/wDLM0dpWOIrhSVJkqYjA+9F6t1TemBt1kofWJMkSZqODLwXqVh+pXB2kT28kiRJ05GB9yK1925nINsOrQsrXYokSZLOwMB7EY4NjHJFYTe97ddCRKXLkSRJ0hkYeC/C9gMnuSa6wFcKS5IkTVsG3otwePdm6iNH28oXVboUSZIknYWB9yKMdpVmaGhdbuCVJEmargy8F6Hh+FZy1ELHqkqXIkmSpLMw8F6gfKHI/KEdHGu6ArK1lS5HkiRJZ2HgvUDPdA9wbexltMNXCkuSJE1nBt4LtHvPbjqiz1cKS5IkTXMG3gvU98yPAZh75boKVyJJkqQXYuC9QHGk9Erh2sU3VrgSSZIkvRAD7wWa1bedY7ULoaG90qVIkiTpBRh4L0DvUI6V+Wfob7+20qVIkiTpHAy8F+Cp/YdZGYdhwQ2VLkWSJEnnYOC9AN07f0wmErOv8A1rkiRJ052B9wKMHdgEQPvKmytciSRJks7FwHsBGk5sYzCaiVnLK12KJEmSzsHAe54KxcTC4R10N18NEZUuR5IkSedg4D1P+471czX7GOtYXelSJEmSNAEG3vO0b+eTNMUoTcscvytJknQ5mFDgjYg7IuKpiNgZEXef4fM/jIiN5eXpiOiZ/FKnh/69jwPQuWp9hSuRJEnSRNScq0FEZIH7gNuBLuDRiPh6SmnrqTYppV8f1/5fA1Xb/Zk5spk8WeoXOqRBkiTpcjCRHt5bgJ0ppd0ppTHgy8CbXqD9ncBDk1HcdDS772mO1C2HmvpKlyJJkqQJmEjgXQzsH7ffVT72PBGxHFgJ/NNZPv9QRGyIiA3d3d3nW2vFDYzmWVnYTf8sXyksSZJ0uZhI4D3T3FvpLG3fATycUiqc6cOU0udSSutTSus7OzsnWuO0seuZZ1gQJ8ksvLHSpUiSJGmCJhJ4u4Cl4/aXAAfP0vYdVPFwhu6djwH4SmFJkqTLyEQC76PAqohYGRF1lELt109vFBHXALOBH0xuidNH8dBmADquWlfhSiRJkjRR5wy8KaU88BHgEWAb8JWU0paIuCci3jiu6Z3Al1NKZxvucNmr79lBT8wimjsqXYokSZIm6JzTkgGklL4BfOO0Y588bf93Jq+s6WnW0F6ONS5nVqULkSRJ0oT5prUJGhrLs7TYxWjbFZUuRZIkSefBwDtBe/d3MScGyHReXelSJEmSdB4MvBPUvedJAFqX+IY1SZKky4mBd4KGD20HoHPF9RWuRJIkSefDwDtBcXwHY9RQ37Gy0qVIkiTpPBh4J6i1/xm6axdDdkITW0iSJGmaMPBOQKGYmJ/bT3+LvbuSJEmXGwPvBBw83sdSjlCcc1WlS5EkSdJ5MvBOwME926iNAg0Lr610KZIkSTpPBt4J6OvaBsDc5WsqXIkkSZLOl4F3AvJHnwKgfcl1Fa5EkiRJ58vAOwH1Pbs4mZkNjbMqXYokSZLOk4F3AuYM7+Nkw7JKlyFJkqQLYOA9h96hHMtSFyOzrqx0KZIkSboABt5z2NO1jzkxQE3n1ZUuRZIkSRfAwHsOx/c8CUDb0tUVrkSSJEkXwsB7DiOHSzM0dDglmSRJ0mXJwHsO2eM7GKOGmrkrKl2KJEmSLoCB9xxaBvfQXbsEMtlKlyJJkqQLYOB9AblCkQW5LgZaV1S6FEmSJF0gA+8L2NfdyzKOkOasqnQpkiRJukAG3hdwaM82aqNA4yJfKSxJknS5MvC+gP6ubQB0rLi+wpVIkiTpQhl4X0Cx+2kAmhdeW+FKJEmSdKEMvC+gvnc3PZnZ0Dir0qVIkiTpAhl4zyKlxNyRvZxsXF7pUiRJknQRDLxncXxwjOXpAGOzrqx0KZIkSboIBt6z2LtvH3NigJp5V1e6FEmSJF0EA+9ZHN+3FYD2pc7QIEmSdDmbUOCNiDsi4qmI2BkRd5+lzdsjYmtEbImIL01umZfeyOHtAMxZZuCVJEm6nNWcq0FEZIH7gNuBLuDRiPh6SmnruDargE8AL08pnYyIeVNV8KVSc2InOWqoneNDa5IkSZezifTw3gLsTCntTimNAV8G3nRamw8C96WUTgKklI5ObpmXXtvgHrrrlkAmW+lSJEmSdBEmEngXA/vH7XeVj413NXB1RPyfiPjniLjjTCeKiA9FxIaI2NDd3X1hFV8CI7kCi3L7GWxdWelSJEmSdJEmEnjjDMfSafs1wCrgNuBO4IGIeN7bGlJKn0sprU8pre/s7DzfWi+ZPUd7WBpHYa4zNEiSJF3uJhJ4u4Cl4/aXAAfP0OZrKaVcSukZ4ClKAfiydHjPdmqjQNMiXyksSZJ0uZtI4H0UWBURKyOiDngH8PXT2nwVeDVARHRQGuKwezILvZQGDpSex5u7Yk2FK5EkSdLFOmfgTSnlgY8AjwDbgK+klLZExD0R8cZys0eA4xGxFfgW8JsppeNTVfRUK3TvAKBhwTUVrkSSJEkX65zTkgGklL4BfOO0Y58ct52Aj5WXy15T3y56MnOY1dBe6VIkSZJ0kXzT2mlSSswd2UdPk/PvSpIkVQMD72kO942wkoPkZl1Z6VIkSZI0CQy8p9m7bz+zY4Da+Y7flSRJqgYG3tOc2LcFgFnLVle4EkmSJE0GA+9pxo5sB6B96fUVrkSSJEmTwcB7mpoTuxijlpi1rNKlSJIkaRIYeE/TPvgMx+uXQCZb6VIkSZI0CQy84wyM5llUOMBg6xWVLkWSJEmTxMA7zjNHelgWR4mOVZUuRZIkSZPEwDvOkT3bqI0CLYuvrXQpkiRJmiQG3nEGDm4DYM6yNRWuRJIkSZPFwDtO6n4agNr5V1e4EkmSJE0WA+84TX3P0JOdAw3tlS5FkiRJk8TAW1YoJjpH99LbtLzSpUiSJGkSGXjLuk4OsTIOkZ99VaVLkSRJ0iQy8Jbt69rH7BigbsE1lS5FkiRJk8jAW9azbysAs5ZeX+FKJEmSNJkMvGVjR54CoHXxdRWuRJIkSZPJwFtWe2InY9TCrGWVLkWSJEmTyMBb1j60lxMNSyGTrXQpkiRJmkQGXuDk4BhLigcYbl1Z6VIkSZI0yQy8wDNHTrA8jhCdvmFNkiSp2hh4gSN7n6ImirT4wJokSVLVMfACgwe3ATB72ZoKVyJJkqTJZuAFOLYDgGznqgoXIkmSpMlm4AUa+56hNzsHGtoqXYokSZIm2YwPvMcHRlmQ28dA6xWVLkWSJElTYMYH3k37jnNt7KNmwepKlyJJkqQpMOMD776nN9Ico8xedWulS5EkSdIUmFDgjYg7IuKpiNgZEXef4fP3RUR3RGwsL3dNfqlTY3TvYwDULVtf4UokSZI0FWrO1SAissB9wO1AF/BoRHw9pbT1tKZ/mVL6yBTUOGWKxUT7iScYyTbRMNcZGiRJkqrRRHp4bwF2ppR2p5TGgC8Db5rasi6NXd0DXJt20jf7esjM+NEdkiRJVWkiKW8xsH/cflf52On+ZUQ8EREPR8TSM50oIj4UERsiYkN3d/cFlDu5Nu3t5rrYR63DGSRJkqrWRAJvnOFYOm3/fwIrUko3Av8APHimE6WUPpdSWp9SWt/Z2Xl+lU6Bw08/Rn3kab/yJZUuRZIkSVNkIoG3CxjfY7sEODi+QUrpeEpptLz7Z8C6ySlvaqUDpQfWMotfVOFKJEmSNFUmEngfBVZFxMqIqAPeAXx9fIOIWDhu943AtskrcWoMjuZZMLCVoZpZMGtZpcuRJEnSFDnnLA0ppXxEfAR4BMgCn08pbYmIe4ANKaWvA78aEW8E8sAJ4H1TWPOkeKKrlxtiN8Oda2mKM43akCRJUjU4Z+AFSCl9A/jGacc+OW77E8AnJre0qfXknkO8P7oYW/GvKl2KJEmSptCMnYvr5M4fkY1E44oXV7oUSZIkTaEZGXhTStQe2VjaWXRzZYuRJEnSlJqRgfdg7whX5HYw2DAfWudXuhxJkiRNoRkZeB/fd5IbYxf5+fbuSpIkVbsZGXi37d7HyswRWq5w/K4kSVK1m5GBd2jPBgCySy6L92NIkiTpIsy4wDuWL9J6/InSjg+sSZIkVb0ZF3i3H+7jenYx2LIcGmdVuhxJkiRNsRkXeB/f18ONmd3EYoczSJIkzQQTetNaNdm1eycL4wRpxfpKlyJJkqRLYMb18Ob3PwZgD68kSdIMMaMC74nBMRYMbqUYWVhwY6XLkSRJ0iUwowLvxv0nWRu7GZ61CuqaKl2OJEmSLoGZFXj3nuTGzG7qlzl+V5IkaaaYUQ+tde3ZzuwYgKWO35UkSZopZkwPb7GYyBx6vLTjCyckSZJmjBkTeHcfG2BVfgeFTC3Mu77S5UiSJOkSmTGB98f7elib2U2uYw3U1FW6HEmSJF0iMybwbtp3nBsyz1C/3AfWJEmSZpIZ89DasT1baGYEFr+o0qVIkiTpEpoRPbyDo3lajz9R2llk4JUkSZpJZkTg3XyglxtiF/maZuhYVelyJEmSdAnNiMD7ePmBtbRwLWSylS5HkiRJl9CMCLyb9x1ldWYvtb5wQpIkacap+sCbUqJ/3xPUkXf8riRJ0gxU9YH3YO8Iy4a3l3acoUGSJGnGqfrAu3FfDzfGbvL1s2HW8kqXI0mSpEus6gPv4/tOsja7m8ziF0FEpcuRJEnSJVb1gXfrvsOsii4ySxzOIEmSNBNVdeAdyxdJB58gS9EH1iRJkmaoCQXeiLgjIp6KiJ0RcfcLtHtrRKSIWD95JV647Yf7uC7tLO34wJokSdKMdM7AGxFZ4D7gdcBq4M6IWH2Gdq3ArwI/nOwiL9TG/T3cmNlFoWUhtC6odDmSJEmqgIn08N4C7Ewp7U4pjQFfBt50hna/C/y/wMgk1ndRHt/Xw4uyzzh+V5IkaQabSOBdDOwft99VPvasiLgZWJpS+psXOlFEfCgiNkTEhu7u7vMu9nzt2LufZRwiHL8rSZI0Y00k8J5pLq/07IcRGeAPgd8414lSSp9LKa1PKa3v7OyceJUX4OTgGO09W0o7jt+VJEmasSYSeLuApeP2lwAHx+23AmuAb0fEHuBW4OuVfnDtQM8wr2wqd0wvurmSpUiSJKmCaibQ5lFgVUSsBA4A7wDeeerDlFIv0HFqPyK+DXw8pbRhcks9P2sWt7Pmqh7S0SuIxtmVLEWSJEkVdM4e3pRSHvgI8AiwDfhKSmlLRNwTEW+c6gIvysHHHb8rSZI0w02kh5eU0jeAb5x27JNnaXvbxZc1CfqPQN8Bx+9KkiTNcNX7prXBbph/AyxeV+lKJEmSVEET6uG9LC1YA7/8vUpXIUmSpAqr3h5eSZIkCQOvJEmSqpyBV5IkSVXNwCtJkqSqZuCVJElSVTPwSpIkqaoZeCVJklTVDLySJEmqagZeSZIkVbVIKVXmwhHdwN5LcKkO4NgluI7On/dmevP+TF/em+nN+zN9Xcy9WZ5S6pzMYnTpVCzwXioRsSGltL7Sdej5vDfTm/dn+vLeTG/en+nLezNzOaRBkiRJVc3AK0mSpKo2EwLv5ypdgM7KezO9eX+mL+/N9Ob9mb68NzNU1Y/hlSRJ0sw2E3p4JUmSNIMZeCVJklTVqjbwRsQdEfFUROyMiLsrXc9MFxGfj4ijEfHkuGNzIuKbEbGjvJ5dyRpnqohYGhHfiohtEbElIn6tfNz7Mw1ERENE/CgiNpXvz78rH18ZET8s35+/jIi6Stc6U0VENiIej4i/Ke97b6aJiNgTEZsjYmNEbCgf82fbDFSVgTcissB9wOuA1cCdEbG6slXNeH8B3HHasbuBf0wprQL+sbyvSy8P/EZK6TrgVuBXyv+/eH+mh1HgNSmltcBNwB0RcSvwH4A/LN+fk8AHKljjTPdrwLZx+96b6eXVKaWbxs2/68+2GagqAy9wC7AzpbQ7pTQGfBl4U4VrmtFSSt8BTpx2+E3Ag+XtB4E3X9KiBEBK6VBK6cfl7X5Kf3EvxvszLaSSgfJubXlJwGuAh8vHvT8VEhFLgJ8DHijvB96b6c6fbTNQtQbexcD+cftd5WOaXuanlA5BKXQB8ypcz4wXESuAm4Ef4v2ZNsq/Mt8IHAW+CewCelJK+XITf8ZVzmeBfwMUy/tz8d5MJwn4+4h4LCI+VD7mz7YZqKbSBUyROMMx51+TXkBEtAB/BXw0pdRX6qjSdJBSKgA3RcQs4H8A152p2aWtShHxeuBoSumxiLjt1OEzNPXeVM7LU0oHI2Ie8M2I2F7pglQZ1drD2wUsHbe/BDhYoVp0dkciYiFAeX20wvXMWBFRSynsfjGl9Nflw96faSal1AN8m9JY61kRcarTwp9xlfFy4I0RsYfS0LnXUOrx9d5MEymlg+X1UUr/WLwFf7bNSNUaeB8FVpWflK0D3gF8vcI16fm+Dry3vP1e4GsVrGXGKo85/C/AtpTSH4z7yPszDUREZ7lnl4hoBP4FpXHW3wLeWm7m/amAlNInUkpLUkorKP09808ppXfhvZkWIqI5IlpPbQM/AzyJP9tmpKp901pE/Cylf2lngc+nlH6vwiXNaBHxEHAb0AEcAf4f4KvAV4BlwD7gbSml0x9s0xSLiFcA3wU289w4xN+iNI7X+1NhEXEjpQdrspQ6Kb6SUronIq6g1Ks4B3gceHdKabRylc5s5SENH08pvd57Mz2U78P/KO/WAF9KKf1eRMzFn20zTtUGXkmSJAmqd0iDJEmSBBh4JUmSVOUMvJIkSapqBl5JkiRVNQOvJEmSqpqBV5IkSVXNwCtJkqSqZuCVJElSVTPwSpIkqaoZeCVJklTVDLySJEmqagZeSZIkVTUDryRJkqqagVeSJElVzcArSZKkqmbglSRJUlUz8EqSJKmqGXglSZJU1Qy8kiRJqmoGXkmSJFU1A68kSZKqmoFXkiRJVc3AK0mSpKpm4JUkSVJVM/BKkiSpqhl4JUmSVNUMvJIkSapqBl5JkiRVNQOvJEmSqpqBV5IkSVXNwCtJkqSqZuCVJElSVTPwSpIkqarVVOrCHR0dacWKFZW6vCRJ0oQ99thjx1JKnZWuQxemYoF3xYoVbNiwoVKXlyRJmrCI2FvpGnThHNIgSZKkqmbglSRJUlUz8EqSJKmqGXglSZJU1Qy8kiRJqmoGXkmSJFU1A68kSZKqWlUH3kIxVboESZIkVVjVBt5DvcO85jPf5msbD5CSwVeSJGmmqtrAO5orMqupjl/78kbuenADh3qHK12SJEmSKqBqA++Kjmb++pdfxr/9uev4P7uO8TN/8B2+9MN9FB3mIEmSNKNUbeAFyGaCu155BY989KdYs7id3/ofm3nnA//M3uODlS5NkiRJl0hVB95Tls9t5ksffAm//5Yb2HKgj9d+9js88N3dPtQmSZI0A8yIwAsQEbzjlmV882Ov4hVXdfDv/3Ybb/nj7/PU4f5KlyZJkqQpNGMC7ykL2hv4s/es5947b6brxBCvv/e7fPYfnmYsX6x0aZIkSZoCMy7wQqm39w1rF/HNj72Kn7thIZ/9hx387t9srXRZkiRJmgI1lS6gkuY01/HZd9xM30ie7+86VulyJEmSNAVmZA/v6W5Y3M7uY4MMjeUrXYokSZImmYEXWLO4nZRg26G+SpciSZKkSWbgBa5f1AbAloMGXkmSpGpj4AUWtjcwu6mWLQcMvJIkSdXGwEtp1oY1i9t58mBvpUuRJEnSJDPwlq1e1MbTR/qdj1eSJKnKGHjLrl/UTq6Q2HHUN69JkiRVEwNv2ZpTD645jleSJKmqGHjLVsxtprkuyxbH8UqSJFUVA29ZJhNct7DNqckkSZKqjIF3nDWL29l6qI9CMVW6FEmSJE0SA+84qxe1MTRWYM/xwUqXIkmSpEli4B3HN65JkiRVHwPvOKvmtVKXzbDlgA+uSZIkVQsD7zh1/3979x4c13ned/z3nL0Bi10AJLCgCIoSaZGORCqRrLKKazuu7fgiu7aVNPbUSt04l5ad1pnYnTgdN3/E00zTTuJO0sTx2KPEGl/G9WVsx1USu5bsqLbTRI4pWbZE0qookpIoXnAhCWAB7P3tH+fscgkCxAJY4Jzd/X5mds7Zs0e7D3BG4A8vnvO+cU8vvSHDCC8AAEAXIfAucXDnkI6enZFz3LgGAADQDQi8S9y+a1CXFso6O1MIuxQAAAC0AYF3iQPjQ5JEHy8AAECXWDXwmtluM3vEzI6b2VEze98y55iZ/YmZnTCzH5nZXZtT7ua7bWdWZszUAAAA0C3iLZxTkfSbzrnHzSwr6TEze9g5d6zpnDdL2h88flrSx4Jtx0kn47oll2GJYQAAgC6x6givc+6cc+7xYH9O0nFJu5acdq+kTzvfo5KGzWxn26vdIgfHWWIYAACgW6yph9fM9kh6maTvLXlpl6QXmp6f0bWhWGZ22MyOmNmRycnJtVW6hW4fH9K5mYKm88WwSwEAAMAGtRx4zSwj6cuS3u+cWzr8acv8J9fM6+Wcu985d8g5dyiXy62t0i3EimsAAADdo6XAa2YJ+WH3s865ryxzyhlJu5ue3yjp7MbLC8cBAi8AAEDXaGWWBpP0CUnHnXN/uMJpD0r6pWC2hpdLmnHOnWtjnVtqOJ3Ujdv69RQ3rgEAAHS8VmZpeKWkfyXpSTN7Ijj225JukiTn3MclfU3SWySdkLQg6VfaX+rWOjg+qGOM8AIAAHS8VQOvc+5vtXyPbvM5TtJ721VUFBwcH9I3jl7QXKGsbF8i7HIAAACwTqy0toLbd/l9vMfPzYVcCQAAADaCwLuCg/UlhunjBQAA6GgE3hWMZVMazSSZqQEAAKDDEXhXYGY6OD6kp15khBcAAKCTEXiv4+D4oE5M5FWsVMMuBQAAAOtE4L2Og+NDqtSc/t/5fNilAAAAYJ0IvNdRn6mBBSgAAAA6F4H3OnZvSyubijNTAwAAQAcj8F6H55luGx9kpgYAAIAORuBdxe3jQzp+blbVmgu7FAAAAKwDgXcVB8cHVSjXdHKSG9cAAAA6EYF3FQeDG9doawAAAOhMBN5V7MtllIp7LEABAADQoQi8q4jHPN16Q5YRXgAAgA5F4G3BgfEhHT07I+e4cQ0AAKDTEHhbcPuuQc0WKjpzaTHsUgAAALBGBN4WHBwfkiQWoAAAAOhABN4W3HpDVjHP9NSL9PECAAB0GgJvC/oSMe3LZRjhBQAA6EAE3hYdZIlhAACAjkTgbdHBXUOamCtqYq4QdikAAABYAwJviw6Os+IaAABAJyLwtuhAEHiPEXgBAAA6CoG3RYN9Cd08kmaJYQAAgA5D4F0DblwDAADoPATeNbj1hkE9f3FBhXI17FIAAADQIgLvGtww2CdJmpwrhlwJAAAAWkXgXYNcNiVJmswTeAEAADoFgXcNGoGXEV4AAICOQeBdAwIvAABA5yHwrsH2gaTMCLwAAACdhMC7BomYp+3pJD28AAAAHYTAu0a5bIoRXgAAgA5C4F0jAi8AAEBnIfCuUS5D4AUAAOgkBN41Gs2mNJkvyjkXdikAAABoAYF3jXKZlEqVmmYLlbBLAQAAQAsIvGvEXLwAAACdhcC7RgReAACAzkLgXaN64J1iLl4AAICOQOBdo1yGEV4AAIBOQuBdo6H+hBIxY7U1AACADrFq4DWzB8xswsyeWuH115jZjJk9ETx+p/1lRofnmUaZixcAAKBjxFs455OS/lTSp69zznedc29tS0UdgNXWAAAAOseqI7zOue9IurgFtXQMVlsDAADoHO3q4f0nZvZDM/u6mR1c6SQzO2xmR8zsyOTkZJs+euvlgtXWAAAAEH3tCLyPS7rZOXeHpI9I+upKJzrn7nfOHXLOHcrlcm346HDksilN54uq1lheGAAAIOo2HHidc7POuXyw/zVJCTMb3XBlEZbLplRz0sX5UtilAAAAYBUbDrxmdoOZWbB/d/Ce0xt93yhjLl4AAIDOseosDWb2OUmvkTRqZmckfUhSQpKccx+X9A5J/87MKpIWJb3LOdfVf+tvLC9MHy8AAEDkrRp4nXP3rfL6n8qftqxnNAIvI7wAAACRx0pr6zBKSwMAAEDHIPCuw0AqroFkjMALAADQAQi86zTKXLwAAAAdgcC7Tv5qa4WwywAAAMAqCLzrlMuyvDAAAEAnIPCuUy6b0lSehScAAACijsC7TrlMSjOLZRUr1bBLAQAAwHUQeNepPhcvo7wAAADRRuBdJxafAAAA6AwE3nUi8AIAAHQGAu86EXgBAAA6A4F3nUYGCLwAAACdgMC7cQTz2QAAGINJREFUTsm4p23phCbzLD4BAAAQZQTeDWDxCQAAgOgj8G4AgRcAACD6CLwbkMukNJkn8AIAAEQZgXcD6iO8zrmwSwEAAMAKCLwbkMumVCjXlC9Wwi4FAAAAKyDwbgBz8QIAAEQfgXcDcpk+SQReAACAKCPwbsBoNilJ3LgGAAAQYQTeDchlaGkAAACIOgLvBmxLJxXzTFOM8AIAAEQWgXcDPM80mkkywgsAABBhBN4NYrU1AACAaCPwbhCrrQEAAEQbgXeDGOEFAACINgLvBuWyKU3lS6rVWF4YAAAgigi8G5TLpFStOV1aKIVdCgAAAJZB4N2gXDZYbY0+XgAAgEgi8G5QLsviEwAAAFFG4N0gAi8AAEC0EXg3iMALAAAQbQTeDRpIxtSfiBF4AQAAIorAu0Fm5s/Fy01rAAAAkUTgbQMWnwAAAIguAm8b5DIEXgAAgKgi8LYBLQ0AAADRReBtg9FMSpcXyipVamGXAgAAgCUIvG1Qn5psep5RXgAAgKgh8LYBc/ECAABEF4G3DQi8AAAA0UXgbQMCLwAAQHStGnjN7AEzmzCzp1Z43czsT8zshJn9yMzuan+Z0TaaSUoi8AIAAERRKyO8n5R0z3Vef7Ok/cHjsKSPbbyszpKKxzTUn2BqMgAAgAhaNfA6574j6eJ1TrlX0qed71FJw2a2s10FdgpWWwMAAIimdvTw7pL0QtPzM8Gxa5jZYTM7YmZHJicn2/DR0cFqawAAANHUjsBryxxzy53onLvfOXfIOXcol8u14aOjg9XWAAAAoqkdgfeMpN1Nz2+UdLYN79tRaGkAAACIpnYE3gcl/VIwW8PLJc0458614X07Si6b0kKpqvliJexSAAAA0CS+2glm9jlJr5E0amZnJH1IUkKSnHMfl/Q1SW+RdELSgqRf2axioyyXuTIX70Bq1W8rAAAAtsiqycw5d98qrztJ721bRR2qsfhEvqg9owMhVwMAAIA6VlprE1ZbAwAAiCYCb5sQeAEAAKKJwNsm29JJxTwj8AIAAEQMgbdNYp5pZCBJ4AUAAIgYAm8bjWZSmmLxCQAAgEgh8LYRq60BAABED4G3jVhtDQAAIHoIvG2Uy/otDbWaC7sUAAAABAi8bZTLpFSuOs0slsMuBQAAAAECbxs1r7YGAACAaCDwthGLTwAAAEQPgbeNCLwAAADRQ+BtIwIvAABA9BB42yibiisV9+jhBQAAiBACbxuZGXPxAgAARAyBt80IvAAAANFC4G2zXIbACwAAECUE3jbLZVP08AIAAEQIgbfNctmULs6XVK7Wwi4FAAAAIvC2XX1qsul8KeRKAAAAIBF42y6XYS5eAACAKCHwtll9hHeKPl4AAIBIIPC22SgjvAAAAJFC4G2zxvLCjPACAABEAoG3zfoSMWX74ozwAgAARASBdxOw2hoAAEB0EHg3AautAQAARAeBdxOw2hoAAEB0EHg3AS0NAAAA0UHg3QS5bEr5YkULpUrYpQAAAPQ8Au8mqK+2NjXH8sIAAABhI/Bugitz8RZCrgQAAAAE3k1QD7wXZunjBQAACBuBdxPsGRlQNhXXVx5/MexSAAAAeh6BdxMMpOI6/OqX6JvHL+ix5y6FXQ4AAEBPI/Bukl991V6NZpL68Dd+LOdc2OUAAAD0LALvJhlIxfXe1+7Toycv6rvPTIVdDgAAQM8i8G6iX/zpm7RruF8f/sbTjPICAACEhMC7iVLxmN7/+v168sUZff2p82GXAwAA0JMIvJvsn991o/aNZfTfH3palWot7HIAAAB6DoF3k8U80wfe+FKdnJzXV37ANGUAAABbjcC7Bd508AbdceOQ/vibz6hYqYZdDgAAQE9pKfCa2T1m9rSZnTCzDy7z+i+b2aSZPRE8/nX7S+1cZqbfetOtevHyoj776PNhlwMAANBTVg28ZhaT9FFJb5Z0QNJ9ZnZgmVO/4Jy7M3j8eZvr7Hiv2j+qV9wyoo8+ckL5YiXscgAAAHpGKyO8d0s64Zw76ZwrSfq8pHs3t6zu9Ftv+glNz5f0wN+eCrsUAACAntFK4N0l6YWm52eCY0v9gpn9yMy+ZGa7l3sjMztsZkfM7Mjk5OQ6yu1sL7tpm954YIf+7DsndWm+FHY5AAAAPaGVwGvLHFu6isJfStrjnPspSd+U9Knl3sg5d79z7pBz7lAul1tbpV3iA2/6CeVLFX3s28+GXQoAAEBPaCXwnpHUPGJ7o6SzzSc456adc8Xg6Z9J+kftKa/7vHRHVj//sl361N+d1vmZQtjlAAAAdL1WAu/3Je03s71mlpT0LkkPNp9gZjubnr5d0vH2ldh9/sPrX6qac/rjbz0TdikAAABdb9XA65yrSPp1Sd+QH2S/6Jw7ama/a2ZvD077DTM7amY/lPQbkn55swruBru3p/WLd9+kLx55Qaem5sMuBwAAoKuZc0vbcbfGoUOH3JEjR0L57CiYnCvq1X/wiF5/YIc+ct/Lwi4HAABch5k95pw7FHYdWB9WWgtJLpvSr75qj/7yh2d19OxM2OUAAAB0LQJviA6/+hYN9Sf03s8+roeOnldYo+0AAADdjMAboqH+hD727rvkeabDn3lM7/z43+ux5y6FXRYAAEBXIfCG7BW3jOqh979a//Xnf1LPXVzQL3zs7/RvP3NEz07mwy4NAACgK3DTWoQslCr6xHdP6ePfflaFSk3/4h/v1vt/dr/GBvvCLg0AgJ7GTWudjcAbQVP5oj7yrWf02e89r0TM07/5mb06/E9vUSYVD7s0AAB6EoG3sxF4I+z01Lw+/NDT+usfndPIQFL//rX79LY7dmosy4gvAABbicDb2Qi8HeCHL1zWf/v6cT168qLMpDt3D+sNB3bojQd26JZcRmYWdokAAHQ1Am9nI/B2COecfnx+Tg8fu6CHj13Qky/6c/fuHR3QGw7s0BsO7NBdN21TzCP8AgDQbgTezkbg7VDnZhb1zWMX9NCxC3r05LTKVaeRgaRed+uY3nBghw7t2a7tA8mwywQAoCsQeDsbgbcLzBbK+vbTk3r42AU98vSE5goVSdLOoT4d2Dmog+ODOjA+qAM7h7R7ez8tEAAArBGBt7Nx238XGOxL6G13jOttd4yrVKnpyHMX9dSLMzp6dlbHzs7qkacnVAt+r8mm4rptPAjBO/0gvG8so1Q8Fu4XAQAAsEkIvF0mGff0iltG9YpbRhvHCuWqfnx+TsfOzuro2RkdOzerz//DC1osVyVJcc90Sy6j23ZmddvOwcYjl02F9WUAAAC0DYG3B/QlYrpz97Du3D3cOFatOZ2amtfxc7ONx6MnL+qrT5xtnDOaSTbC7603ZPWSXEZ7Rwc01J8I48sAAABYFwJvj4p5pn1jGe0by+htd4w3jl+aL+n4+VkdPzfXCMKf/L+nVarWGueMDCS1d3TAf+QG9JLRAe0dzejmkbT6ErRGAACAaOGmNayqXK3puel5nZyc1+npeZ2a8vdPTc1rYq7YOM9MGh/q157RtPaMDGjPyIBuHklr7+iAdm8nDAMAOhc3rXU2RnixqkTM076xrPaNZa95LV+s6PTUvE5OzevU5LxOTeV1enpBf/3kOV1eKDfOM5N2DvZpz+iAbh4Z0J6RtHYO92uoP6HBvrgG+xMa7EtosD/ODXQAAKCtCLzYkEwqrtt3Den2XUPXvHZ5oaTT0wt6LhgVfm56Qaen5/W/nzqnS01heKlU3AsCsB+Eh/sTekkuo/1jGe3fkdG+XFZDafqIAQBAawi82DTD6aTuTCevulmubmahrAtzBc0VyppdrGi2UNbsYlmzhUqwvXL8/GxRf39yWoXylT7iXDblB+CxjPbtyPrbsYxGBpLMMwwAAK5C4EUohtKJNY3S1mpOL15e1DMTc3rmQl4nJvJ6ZiKvLz/+ovLFSuO8ZMzTtoGEtqWT2j5w5VF/vm0gqZGBpMayKfqKAQDoEQRedATPM+3entbu7Wm97tYdjePOOZ2fLfgB+EJeE3NFXZov6eJCSRfnSzp2dlYXF0pX9RPXLb3Jbu+of6PdntEB3bQ9rWTc28ovEQAAbBICLzqamWnnUL92DvXrZ/bnVjyvUq3p8mLZD8PzJZ2fLejU1LxOT83r1PSC/upH5zSzeCUUeybt2tavPSMDGsv2aTSbVC6TUi6b0mjTdrg/Ic+jhQIAgCgj8KInxGOeRjN+SF3JpfmSTk37IbgehJ+fntezE3lN5osqV6+dwi/umUYyyUYI3pHt09hgSmPZlHJX7aeYfQIAgJAQeIHAtqDH966btl3zmnNOs4sVTeYLmpwraTJf1NRcUVP5oibnipoMtkfPzmo6X1Rtmemth9OJRvjdPpDS9nTC32aS2h70GI9k/O1wf0LxGC0VAAC0A4EXaIGZNW602zd2/XOrNafpfFETc0VNzBU0MXv1/mS+qBcvXdb0fElzhcqy72EmDfUngnmKg21/PJirOHH1/MX9/k16I0FgTif53xoAgGb8ywi0WcwzjQ32aWywT9K18xM3K1VqurxQ0vR8SZfmg+1CSdN5v9e4Pl3bzGJZ52cLjf1ipbbie/YnYhrJ1ANwqjFyPDqQ0raB5JUg3R9v7PcnYkznBgDoWgReIETJuNcUjltXKFc1V6hoJgjA9dA8nS9pOl/UxfmSpuZLujBb0PFzs5rOl1SqrhySEzFrGkn2t8Npf9GP4XRSw2l/FHko2A4Hrw/2cdMeACD6CLxAB+pLxNSXiCmXXfkmvGbOOeWLFX/UePFKUJ4JFvlo7DcF6NPT87q8UL5q9oqlzKRMMq7+ZMx/JJq2iauPpZNxDaeDMN3vt4cM9ycbx9JJRpkBAJuDwAv0ADNTti+hbN/al2Su1pxmF8u6tFDS5SAMX14oB4+S5ooVFcpVLZSqWixVtVj2tzOL5cbzhVJVC6XKsjNd1CVipqH+pIb64xpIxa8Jz33Bfjrph/3+REyJuCfPJJP5W/O/VpPkmcnM38Zjpu1pv8VjJOMvRBJjZBoAegaBF8B1xTxrzGCxEc45LZarV8LyYkmzi/X9cjCaXNLMYrkRni/OlxqhuRAE6YVyVW7l3NwSM111o99IJqXRgaS2D6SUTsaUjHtKxT0l64/Ylf1UPKZU3FNfwlM6GddAMq50KqYEs2oAQGQReAFsCTNTOhlXOhnX+HD/ut/HOadStaZCqaZitSo5qeYkJ+dvnZNzknNSzTk5+TcHXpwvaXo+6G8Oep3rNwfW+5yv176xmmTMUzoVUzoRUzoV10DQxtGf9OdfrgV11bdOTrXalbrlpHQq5vdKBzNvDKeDXup0UtvqLSADCWWScXqnAWANCLwAOoqZBaOsMUlrb9G4nnK1pkK5qlKlplK1plKlpmJl6dZ/vd66MV+qarFU0XypqoVisC1VNF/0txNzZZms0W7ht2Bcabmot2CYJ12cL+nZybwuz5c1V1x+yrq6mGeKe6ZEzFMiZorHPCW8YBurH/dHqlOJ5pFpf3vVfiLmv4fnKR4zxTxTwvP8z2g6Hvf87322Lx48Esr2xdWXYFEVANFG4AWAQD0kRkG5WgtuILzSN30p2OaLFVVqNVWq/mh3pepUqdVUrjpVqv62XK2pXPWDe6Hsv1ex7Af3QrmqYhDeC+WVZ+9oVTLuaTAIwPVtJhWXk1O15o9qV2tND+dUC7bVmlMi5ind1KPdn6yPkPv76aabImOe/0uDZ34w9zxTzEyemTxPigXH/Rs7vcYNnv3Btt292+Xqku9puer/otH0S0Yq7nFDJhAyAi8ARFCiheWw28E5p2KlpkrNqVp1Ktdqqtb8wFytOVVqrhGoK1X/3LlCWXOFimaXbhf97VyhrIm5gn8zYTAS7QdTBYHVlIz7I8gxz1Su1pQvVjQ5V2zc4LgQ9G5vtF97qWTMawTh/mRM8SAA10fa/X3/Rsj6vv99koqV6pJfGPzvUSuuHlH31Bf3W18as5Y0P9JX9ofTwS8PS9p0/NYYvx2m5vz2mJpzKlaqWiwFf4EoV1VounG0uRfeMzWmHKy3zQw3tdJk+xLc2ImuQuAFgB5mZpFtSXDOqVCuNQJwoVxVzfkzhzRGjYPgV61dOV6puUbbSaFUVaHih7xCudYIfYUgEFb8BnD5MVKNYCn5x+r7ZlIq7o8aL20P6UvEghFd/7VrRn2Dkd/mY4VyVfliRTMLJT0/Pa/LwbSALebndetLeOpPxPzZV1ZY6bH+9dZXeqy3s8Q8TzFPinme/zwYTY/HrNGi4/en+9eurt6zXj/kmfnfx0RMffHmkXiv8T3uC16LL2nXiTe12dRbeeKeaTST0g1Da5vPHL2FwAsAiCQza8zxPBJ2MVugVnPKlyqaWShfNVd2vlBpTLHneWr0hHv1Vo6m/vBUonkebD84ppP+NH+puHfVzY7VmmvMu73clIOXg8+v1PwWlErt6taUSvDXgGKlevVId70vPehX9w9dOVapOV2cr6lQqapYrjV+ASmsYcR8qXe//Cb9l5/7yXV/79H9CLwAAESA5/krHg72JbR7Cz4v5pm2DyS1fYNTDrZT8+h4oVxd0p8etNYELTfNr924bf0zv6A3EHgBAEAk1G8czaSIJ2ivaNyODAAAAGwSAi8AAAC6GoEXAAAAXY3ACwAAgK5G4AUAAEBXaynwmtk9Zva0mZ0wsw8u83rKzL4QvP49M9vT7kIBAACA9Vg18JpZTNJHJb1Z0gFJ95nZgSWn/ZqkS865fZL+SNLvt7tQAAAAYD1aGeG9W9IJ59xJ51xJ0ucl3bvknHslfSrY/5KknzUzFuEGAABA6FoJvLskvdD0/ExwbNlznHMVSTPStStBmtlhMztiZkcmJyfXVzEAAACwBq0sZbLcSO3Sxa5bOUfOufsl3S9JZjZpZs+18PkbNSppags+B2vHtYk2rk90cW2ijesTXRu5Nje3sxBsrVYC7xnpqmW9b5R0doVzzphZXNKQpIvXe1PnXG4Nda6bmR1xzh3ais/C2nBtoo3rE11cm2jj+kQX16Z3tdLS8H1J+81sr5klJb1L0oNLznlQ0nuC/XdI+hvn3DUjvAAAAMBWW3WE1zlXMbNfl/QNSTFJDzjnjprZ70o64px7UNInJH3GzE7IH9l912YWDQAAALSqlZYGOee+JulrS479TtN+QdI721ta29wfdgFYEdcm2rg+0cW1iTauT3RxbXqU0XkAAACAbsbSwgAAAOhqBF4AAAB0ta4NvGZ2j5k9bWYnzOyDYdfT68zsATObMLOnmo5tN7OHzeyZYLstzBp7lZntNrNHzOy4mR01s/cFx7k+EWBmfWb2D2b2w+D6/Ofg+F4z+15wfb4QzKKDEJhZzMx+YGZ/FTzn2kSEmZ02syfN7AkzOxIc42dbD+rKwGtmMUkflfRmSQck3WdmB8Ktqud9UtI9S459UNK3nHP7JX0reI6tV5H0m8652yS9XNJ7g/9fuD7RUJT0OufcHZLulHSPmb1c0u9L+qPg+lyS9Gsh1tjr3ifpeNNzrk20vNY5d2fT/Lv8bOtBXRl4Jd0t6YRz7qRzriTp85LuDbmmnuac+46uXYzkXkmfCvY/JenntrQoSJKcc+ecc48H+3Py/+HeJa5PJDhfPniaCB5O0uskfSk4zvUJiZndKOmfSfrz4LmJaxN1/GzrQd0aeHdJeqHp+ZngGKJlh3PunOSHLkljIdfT88xsj6SXSfqeuD6REfzJ/AlJE5IelvSspMvOuUpwCj/jwvM/JP1HSbXg+Yi4NlHiJD1kZo+Z2eHgGD/belBL8/B2IFvmGPOvAddhZhlJX5b0fufcrD9QhShwzlUl3Wlmw5L+QtJty522tVXBzN4qacI595iZvaZ+eJlTuTbheaVz7qyZjUl62Mx+HHZBCEe3jvCekbS76fmNks6GVAtWdsHMdkpSsJ0IuZ6eZWYJ+WH3s865rwSHuT4R45y7LOn/yO+1Hjaz+qAFP+PC8UpJbzez0/Jb514nf8SXaxMRzrmzwXZC/i+Ld4ufbT2pWwPv9yXtD+6UTcpf6vjBkGvCtR6U9J5g/z2S/leItfSsoOfwE5KOO+f+sOklrk8EmFkuGNmVmfVLer38PutHJL0jOI3rEwLn3H9yzt3onNsj/9+Zv3HO/UtxbSLBzAbMLFvfl/RGSU+Jn209qWtXWjOzt8j/TTsm6QHn3O+FXFJPM7PPSXqNpFFJFyR9SNJXJX1R0k2Snpf0Tufc0hvbsMnM7FWSvivpSV3pQ/xt+X28XJ+QmdlPyb+xJiZ/kOKLzrnfNbOXyB9V3C7pB5Le7ZwrhldpbwtaGj7gnHsr1yYaguvwF8HTuKT/6Zz7PTMbET/bek7XBl4AAABA6t6WBgAAAEASgRcAAABdjsALAACArkbgBQAAQFcj8AIAAKCrEXgBAADQ1Qi8AAAA6Gr/H8G25V4dsO6nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10), num='5.4 Training Result')\n",
    "plt.subplot(211)\n",
    "plt.plot(FIG_X[0:len(ACC_TRAIN)], ACC_TRAIN, label=\"Training\")\n",
    "plt.plot(FIG_X[0:len(ACC_TEST)], ACC_TEST, label=\"Testing\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(FIG_X[0:len(LOSS_TRAIN)], LOSS_TRAIN)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"./model\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.100 Acc 0.971\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "testIndex = 0\n",
    "print(testIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxAAAAFlCAYAAAB7iQ6mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWKklEQVR4nO3df7DldX3f8dfbvVB/R4S1Q/nhUkszMo4juBJa1NKiHcAM2Go7MGN/ZBzW6YA1IUOHtEVT+oeJ7TStM5iUqtWkRkRN2h27XcwQYtoqlsWfwAa7SwzcoIUEqlJLgfbdP+7BuV4u8XMO95zD7j4eMzvcc86b7/fNzjK7z/1+zz3V3QEAABjxrGUvAAAAHDoEBAAAMExAAAAAwwQEAAAwTEAAAADDBAQAADBsZZrhqvI9XwE26O5a9g6Hk+OOO6537Nix7DUAjmi33XbbH3X39s1emyogAGDeduzYkX379i17DYAjWlX9wVO95hYmAABgmIAAAACGCQgAAGCYgAAAAIYJCAAAYJiAAAAAhgkIAABgmIAAAACGCQgAAGCYgAAAAIYJCABmVlUfrqr7q+r2p3i9qur9VXWgqr5WVWcsekcAtpaAAODp+EiS8/6E189Pcurkx64kv7yAnQCYIwEBwMy6+3eTPPgnjFyU5Fd7zS1JXlRVxy9mOwDmYWXZCwBwWDshyb3rHq9OnvvW+qGq2pW1KxQ5+eSTF7YcsDg7rvqPCznPN3/hTQs5z5HMFQgA5qk2ea6f9ET3dd29s7t3bt++fQFrATArAQHAPK0mOWnd4xOT3LekXQDYAgICgHnaneRvT74b01lJvtPd3/pR/xIAz1zeAwHAzKrq40nOSXJcVa0meU+So5Kku38lyZ4kFyQ5kOT7SX5qOZsCsFUEBAAz6+5LfsTrneSyBa0DwAK4hQkAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAmFlVnVdVd1XVgaq6apPXT66qm6vqy1X1taq6YBl7ArB1BAQAM6mqbUmuTXJ+ktOSXFJVp20Y+8dJbuju05NcnOQDi90SgK0mIACY1ZlJDnT33d39aJLrk1y0YaaTvHDy9Y8luW+B+wEwBwICgFmdkOTedY9XJ8+t9/NJ3lZVq0n2JHnnZgeqql1Vta+q9j3wwAPz2BWALSIgAJhVbfJcb3h8SZKPdPeJSS5I8mtV9aTfe7r7uu7e2d07t2/fPodVAdgqAgKAWa0mOWnd4xPz5FuU3p7khiTp7i8keXaS4xayHQBzISAAmNWtSU6tqlOq6uisvUl694aZe5KcmyRV9fKsBYR7lAAOYSvLXuBw8Na3vnWq+UsvvXR49r77pnu/4SOPPDLV/Mc+9rHh2W9/+9tTHfvAgQNTzQOHlu5+vKouT3Jjkm1JPtzdd1TVNUn2dffuJD+b5N9U1c9k7famv9vdG29zAuAQIiAAmFl378nam6PXP/fudV/fmeTsRe8FwPy4hQkAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGOaTqLfA+973vqnmd+zYMZ9FZvCOd7xjePZ73/veVMe+4447pl2HLbC6ujo8O+2v3X379k27DgBwmHEFAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABi2suwFDgeXXnrpVPOvfOUrh2f3798/1bFf/vKXTzV/xhlnDM+ec845Ux37rLPOmmr+3nvvHZ496aSTpjr2PD3++ONTzT/wwANTzR9//PFTzU/jnnvumWp+3759c9oEADhUuAIBAAAMExAAAMAwAQEAAAwTEAAAwDABAQAADBMQAADAMAEBAAAMExAAAMAwAQEAAAwTEAAAwDABAQAADFtZ9gKHg5tuummu89PYu3fv3I59zDHHTDX/qle9aqr52267bXj2Na95zVTHnqdHHnlkqvlvfOMbU83v379/qvkXv/jFw7MHDx6c6tgAAK5AAAAAwwQEAAAwTEAAAADDBAQAADBMQAAAAMMEBAAAMExAAAAAwwQEAAAwTEAAAADDBAQAADBsZdkLcOh46KGHppq/+eab57RJctNNN83t2PP2lre8Zar5Y445Zqr5r3/968Ozn/jEJ6Y6NgCAKxAAAMAwAQEAAAwTEAAAwDABAQAADBMQAADAMAEBAAAMExAAAMAwAQEAAAwTEADMrKrOq6q7qupAVV31FDN/s6rurKo7qurXF70jAFvLJ1EDMJOq2pbk2iRvTLKa5Naq2t3dd66bOTXJzyU5u7sfqqqXLGdbALaKKxAAzOrMJAe6++7ufjTJ9Uku2jBzaZJru/uhJOnu+xe8IwBbzBUIeJpe8pLp/kL1Ax/4wFTzz3rWdJ1/zTXXDM8++OCDUx0bNjghyb3rHq8m+YkNM38+SarqvybZluTnu3vvxgNV1a4ku5Lk5JNPnsuyAGwNVyAAmFVt8lxveLyS5NQk5yS5JMkHq+pFT/qXuq/r7p3dvXP79u1bvigAW0dAADCr1SQnrXt8YpL7Npn5D939WHf/fpK7shYUAByiBAQAs7o1yalVdUpVHZ3k4iS7N8z8+yR/OUmq6ris3dJ090K3BGBLCQgAZtLdjye5PMmNSfYnuaG776iqa6rqwsnYjUn+uKruTHJzkiu7+4+XszEAW8GbqAGYWXfvSbJnw3PvXvd1J7li8gOAw4ArEAAAwDABAQAADBMQAADAMAEBAAAMExAAAMAwAQEAAAzzbVzhabrsssummt++fftU8w899NBU83fddddU8wAA03AFAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhK8teAJ6Jzj777OHZq666ao6bJG9+85unmr/99tvntAkAgCsQAADAFAQEAAAwTEAAAADDBAQAADBMQAAAAMMEBAAAMExAAAAAwwQEAAAwTEAAAADDBAQAADBMQAAAAMNWlr0APBNdcMEFw7NHHXXUVMe+6aabppr/whe+MNU8AMA8uQIBAAAMExAAAMAwAQEAAAwTEAAAwDABAQAADBMQAADAMAEBAAAMExAAAMAwAQEAAAwTEAAAwDABAQAADFtZ9gKwCM95znOmmj/vvPOGZx999NGpjv2e97xnqvnHHntsqnkAgHlyBQIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYtrLsBWARrrzyyqnmTz/99OHZvXv3TnXsz3/+81PNwzNZVZ2X5F8l2Zbkg939C08x99Ykn0zymu7et8AVAdhirkAAMJOq2pbk2iTnJzktySVVddomcy9I8veTfHGxGwIwDwICgFmdmeRAd9/d3Y8muT7JRZvM/dMk70vyyCKXA2A+BAQAszohyb3rHq9OnvuBqjo9yUnd/ZlFLgbA/AgIAGZVmzzXP3ix6llJfinJz/7IA1Xtqqp9VbXvgQce2MIVAdhqAgKAWa0mOWnd4xOT3Lfu8QuSvCLJ71TVN5OclWR3Ve3ceKDuvq67d3b3zu3bt89xZQCeLgEBwKxuTXJqVZ1SVUcnuTjJ7ide7O7vdPdx3b2ju3ckuSXJhb4LE8ChTUAAMJPufjzJ5UluTLI/yQ3dfUdVXVNVFy53OwDmxedAADCz7t6TZM+G5979FLPnLGInAObLFQgAAGCYgAAAAIa5hYlD0pve9Kap5q+++uqp5r/73e8Oz15zzTVTHRsA4FDmCgQAADBMQAAAAMMEBAAAMExAAAAAwwQEAAAwTEAAAADDBAQAADBMQAAAAMMEBAAAMExAAAAAwwQEAAAwbGXZC8ATjj322OHZ97///VMde9u2bVPN79mzZ3j2lltumerYAACHMlcgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGEry16Aw9e2bdummt+7d+/w7CmnnDLVsQ8ePDjV/NVXXz3VPADAkcIVCAAAYJiAAAAAhgkIAABgmIAAAACGCQgAAGCYgAAAAIYJCAAAYJiAAAAAhgkIAABgmIAAAACGrSx7AQ5fL3vZy6aaf/WrXz2nTZIrrrhiqvmDBw/OaRMAgEObKxAAAMAwAQEAAAwTEAAAwDABAQAADBMQAADAMAEBAAAMExAAAMAwAQEAAAwTEAAAwDABAQAADBMQAADAsJVlL8Ch46UvfelU85/97GfntEly5ZVXTjX/mc98Zk6bAAAcWVyBAAAAhgkIAABgmIAAAACGCQgAZlZV51XVXVV1oKqu2uT1K6rqzqr6WlXdVFXTvZkKgGccAQHATKpqW5Jrk5yf5LQkl1TVaRvGvpxkZ3e/MsmnkrxvsVsCsNUEBACzOjPJge6+u7sfTXJ9kovWD3T3zd39/cnDW5KcuOAdAdhiAgKAWZ2Q5N51j1cnzz2Vtyf5T3PdCIC58zkQAMyqNnmuNx2seluSnUn+0lO8vivJriQ5+eSTt2o/AObAFQgAZrWa5KR1j09Mct/Goap6Q5J/lOTC7v4/mx2ou6/r7p3dvXP79u1zWRaArSEgAJjVrUlOrapTquroJBcn2b1+oKpOT/KvsxYP9y9hRwC2mIAAYCbd/XiSy5PcmGR/khu6+46quqaqLpyM/bMkz0/yyar6SlXtforDAXCI8B4Ihu3atWuq+Xnex/y5z31uqvnuTW/LBp6m7t6TZM+G59697us3LHwpAObKFQgAAGCYgAAAAIYJCAAAYJiAAAAAhgkIAABgmIAAAACGCQgAAGCYgAAAAIYJCAAAYJiAAAAAhq0sewGW67Wvfe3w7Dvf+c45bgIAwKHAFQgAAGCYgAAAAIYJCAAAYJiAAAAAhgkIAABgmIAAAACGCQgAAGCYgAAAAIYJCAAAYJiAAAAAhgkIAABg2MqyF2C5Xve61w3PPv/5z5/jJsnBgweHZx9++OE5bgIAwFNxBQIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYJiAAAIBhAgIAABgmIAAAgGECAgAAGCYgAACAYQICAAAYtrLsBTh8ffWrX51q/txzzx2effDBB6ddBwCALeAKBAAAMExAAAAAwwQEAAAwTEAAAADDBAQAADBMQAAAAMMEBAAAMExAAAAAwwQEAAAwTEAAAADDVpa9AMv13ve+dy6zAAAcnlyBAAAAhgkIAABgmIAAAACGCQgAAGCYgAAAAIYJCAAAYJiAAAAAhgkIAGZWVedV1V1VdaCqrtrk9T9VVZ+YvP7Fqtqx+C0B2EoCAoCZVNW2JNcmOT/JaUkuqarTNoy9PclD3f3nkvxSkl9c7JYAbDUBAcCszkxyoLvv7u5Hk1yf5KINMxcl+ejk608lObeqaoE7ArDFBAQAszohyb3rHq9Ontt0prsfT/KdJMcuZDsA5mJlyvk/SvIH81gE4BD10mUvsESbXUnoGWZSVbuS7Jo8fLiq7nqau83iuKz9PrdMdlj++e1wiO9QW3+j5CH587AFnvL3t6kCoru3P/1dADhMrCY5ad3jE5Pc9xQzq1W1kuTHkjy48UDdfV2S6+a055Cq2tfdO+2w3B2WfX472MEOP5pbmACY1a1JTq2qU6rq6CQXJ9m9YWZ3kr8z+fqtSX67u590BQKAQ8e0tzABQJK19zRU1eVJbkyyLcmHu/uOqromyb7u3p3kQ0l+raoOZO3Kw8XL2xiArSAgAJhZd+9JsmfDc+9e9/UjSf7Govea0VJvoZqww/LPn9jhCXZYY4cNypVkAABglPdAAAAAwwQEAEe0qjqvqu6qqgNVddWSdvhwVd1fVbcv6fwnVdXNVbW/qu6oqnctYYdnV9V/q6qvTnb4J4veYd0u26rqy1X1mSWd/5tV9fWq+kpV7VvSDi+qqk9V1e9Nfl38hQWf/8cn//1P/PhuVf30IneY7PEzk1+Pt1fVx6vq2UvY4V2T89+xjJ+DzbiFCYAjVlVtS/KNJG/M2recvTXJJd1954L3eH2Sh5P8ane/YpHnnpz/+CTHd/eXquoFSW5L8uZF/jxMPqH8ed39cFUdleS/JHlXd9+yqB3W7XJFkp1JXtjdP7mE838zyc7uXtpnD1TVR5P85+7+4OS7rD23u//nknbZluQPk/xEdy/s88iq6oSs/To8rbv/d1XdkGRPd39kgTu8Isn1Sc5M8miSvUn+Xnf/90XtsBlXIAA4kp2Z5EB3393dj2btN+qLFr1Ed/9uNvl8jAWe/1vd/aXJ199Lsj9P/lTxee/Q3f3w5OFRkx8L/1vOqjoxyZuSfHDR536mqKoXJnl91r6LWrr70WXFw8S5SQ4uMh7WWUnynMnn2Dw3T/6sm3l7eZJbuvv73f14ks8l+WsL3uFJBAQAR7ITkty77vFqFvwH52eaqtqR5PQkX1zCubdV1VeS3J/kt7p74Tsk+ZdJ/kGS/7eEcz+hk3y2qm6bfEr7ov3ZJA8k+beTW7k+WFXPW8IeT7g4yccXfdLu/sMk/zzJPUm+leQ73f3ZBa9xe5LXV9WxVfXcJBfkhz/AcykEBABHstrkuSP23t6qen6STyf56e7+7qLP393/t7tflbVPNT9zcvvGwlTVTya5v7tvW+R5N3F2d5+R5Pwkl01ucVuklSRnJPnl7j49yf9Ksqz3Bx2d5MIkn1zCuY/J2hXJU5L8mSTPq6q3LXKH7t6f5BeT/FbWbl/6apLHF7nDZgQEAEey1fzw3+admMXfovCMMHnfwaeTfKy7f2OZu0xul/mdJOct+NRnJ7lw8h6E65P8lar6dwveId193+Sf9yf5zazdardIq0lW110B+lTWgmIZzk/ype7+H0s49xuS/H53P9DdjyX5jSR/cdFLdPeHuvuM7n591m51XOr7HxIBAcCR7dYkp1bVKZO/6bw4ye4l77RwkzcwfyjJ/u7+F0vaYXtVvWjy9XOy9oe331vkDt39c919YnfvyNqvhd/u7oX+jXNVPW/yRvZMbhv6q1m7jWVhuvvbSe6tqh+fPHVukoV+Y4F1LskSbl+auCfJWVX13Mn/I+dm7f1BC1VVL5n88+Qkfz3L+/n4AZ9EDcARq7sfr6rLk9yYZFuSD3f3HYveo6o+nuScJMdV1WqS93T3hxa4wtlJ/laSr0/eg5Ak/3DySeOLcnySj06+486zktzQ3Uv5NqpL9qeT/Oban1ezkuTXu3vvEvZ4Z5KPTcL67iQ/tegFJvf8vzHJOxZ97iTp7i9W1aeSfClrtw19Ocv5ROhPV9WxSR5Lcll3P7SEHX6Ib+MKAAAMcwsTAAAwTEAAAADDBAQAADBMQAAAAMMEBAAAMExAAAAAwwQEAAAwTEAAAADD/j/RAJLwcAsvRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 6), num='5.5')\n",
    "TEST_IMAGE, test_image_label = test_data[testIndex]\n",
    "test_image = np.array(TEST_IMAGE, dtype='float')\n",
    "pixels = test_image.reshape((28, 28))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "fig.show()\n",
    "\n",
    "# Test Model\n",
    "model.eval()\n",
    "test = DataLoader(test_data[testIndex])\n",
    "test_x, test_y = test\n",
    "output = model(test_x)\n",
    "output = F.softmax(output, dim=1)\n",
    "output = output.tolist()[0]\n",
    "\n",
    "outputProbLabel = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "plt.bar(outputProbLabel, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
