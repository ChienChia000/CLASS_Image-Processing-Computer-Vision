{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import QApplication, QDialog, QMessageBox, QPushButton\n",
    "from hw1UI import Ui_Dialog\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "OPTIMIZER = \"SGD\"\n",
    "PRINT_FREQ = 100\n",
    "TRAIN_NUMS = 50000\n",
    "def downloadMNIST():\n",
    "    data_transform = transforms.Compose([transforms.ToTensor()])\n",
    "    train_data = datasets.MNIST(root=\"./\", train=True,download=True, transform=data_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS)))\n",
    "    \n",
    "    val_loader = DataLoader(train_data, batch_size=BATCH_SIZE, sampler=SubsetRandomSampler(range(TRAIN_NUMS, 60000)))\n",
    "\n",
    "    test_data = datasets.MNIST(root=\"./\", train=False, download=True, transform=data_transform)\n",
    "    \n",
    "    test_loader = DataLoader(test_data, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return train_data, train_loader, test_data, test_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_loader, test_data, test_loader, val_loader = downloadMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Show 10 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x1008 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 14), num='5.1 10 Images and Labels of MNIST')\n",
    "columns = 5\n",
    "rows = 2\n",
    "for i in range(1, columns*rows +1):\n",
    "    randomNum = random.randint(0,60000)\n",
    "    train_image, train_image_label = train_data[randomNum]\n",
    "    train_image = np.array(train_image, dtype='float')\n",
    "    pixels = train_image.reshape((28, 28))\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.xlabel(train_image_label)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.imshow(pixels, cmap='gray')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Print Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hyperparameters:\n",
      "batch size: 32\n",
      "learning rate: 0.001\n",
      "optimizer: SGD\n"
     ]
    }
   ],
   "source": [
    "print(\"hyperparameters:\")\n",
    "print(\"batch size:\", BATCH_SIZE)\n",
    "print(\"learning rate:\", LEARNING_RATE)\n",
    "print(\"optimizer:\", OPTIMIZER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Train 1 epoch and show training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    x = torch.flatten(x, start_dim=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS=[]\n",
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, criterion, optimizer, device):\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "    def train_loop(self, model, train_loader, val_loader):\n",
    "        for epoch in range(EPOCHS):\n",
    "#             print(\"---------------- Epoch {} ----------------\".format(epoch))\n",
    "            self._training_step(model, train_loader, epoch)\n",
    "            \n",
    "            self._validate(model, val_loader, epoch)\n",
    "    \n",
    "    def test(self, model, test_loader):\n",
    "            print(\"---------------- Testing ----------------\")\n",
    "            self._validate(model, test_loader, 0, state=\"Testing\")\n",
    "            \n",
    "    def _training_step(self, model, loader, epoch):\n",
    "        model.train()\n",
    "        global flag\n",
    "        for step, (X, y) in enumerate(loader):\n",
    "            X, y = X.to(self.device), y.to(self.device)\n",
    "            N = X.shape[0]\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outs = model(X)\n",
    "            loss = self.criterion(outs, y)\n",
    "            \n",
    "            ###################################\n",
    "            LOSS.append(loss.data.item())\n",
    "            FIG_X.append(flag)\n",
    "            flag=flag+1\n",
    "            ###################################\n",
    "            \n",
    "            if step >= 0 and (step % PRINT_FREQ == 0):\n",
    "                self._state_logging(outs, y, loss, step, epoch, \"Training\")\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "    def _validate(self, model, loader, epoch, state=\"Validate\"):\n",
    "        model.eval()\n",
    "        outs_list = []\n",
    "        loss_list = []\n",
    "        y_list = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step, (X, y) in enumerate(loader):\n",
    "                X, y = X.to(self.device), y.to(self.device)\n",
    "                N = X.shape[0]\n",
    "                \n",
    "                outs = model(X)\n",
    "                loss = self.criterion(outs, y)\n",
    "                \n",
    "                y_list.append(y)\n",
    "                outs_list.append(outs)\n",
    "                loss_list.append(loss)\n",
    "            \n",
    "            y = torch.cat(y_list)\n",
    "            outs = torch.cat(outs_list)\n",
    "            loss = torch.mean(torch.stack(loss_list), dim=0)\n",
    "            self._state_logging(outs, y, loss, step, epoch, state)\n",
    "            ####################################\n",
    "            if(state == \"Validate\"):\n",
    "                LOSS_TRAIN.append(loss)\n",
    "                ACC_TRAIN.append(self._accuracy(outs, y))\n",
    "            elif(state == \"Testing\"):\n",
    "                ACC_TEST.append(self._accuracy(outs, y))\n",
    "            ####################################\n",
    "                \n",
    "    def _state_logging(self, outs, y, loss, step, epoch, state):\n",
    "        acc = self._accuracy(outs, y)\n",
    "        print(\"[{:3d}/{}] {} Step {:03d} Loss {:.3f} Acc {:.3f}\".format(epoch+1, EPOCHS, state, step, loss, acc))\n",
    "            \n",
    "    def _accuracy(self, output, target):\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        pred = output.argmax(1)\n",
    "        correct = pred.eq(target)\n",
    "        acc = correct.float().sum(0) / batch_size\n",
    "\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1, self.conv2 = None, None\n",
    "        self.fc1, self.fc2 = None, None\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=0, bias=False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1152, 200, bias = False),\n",
    "            nn.ReLU(inplace=False)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(200, 10, bias = False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = None\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 000 Loss 2.305 Acc 0.031\n",
      "[  1/1] Training Step 100 Loss 2.282 Acc 0.406\n",
      "[  1/1] Training Step 200 Loss 2.258 Acc 0.531\n",
      "[  1/1] Training Step 300 Loss 2.211 Acc 0.469\n",
      "[  1/1] Training Step 400 Loss 1.946 Acc 0.500\n",
      "[  1/1] Training Step 500 Loss 0.840 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.607 Acc 0.844\n",
      "[  1/1] Training Step 700 Loss 0.531 Acc 0.812\n",
      "[  1/1] Training Step 800 Loss 0.292 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.811 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.488 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.443 Acc 0.812\n",
      "[  1/1] Training Step 1200 Loss 0.646 Acc 0.781\n",
      "[  1/1] Training Step 1300 Loss 0.474 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.136 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.094 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.297 Acc 0.913\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.298 Acc 0.912\n"
     ]
    }
   ],
   "source": [
    "LOSS=[]\n",
    "FIG_X=[]\n",
    "flag=0\n",
    "\n",
    "device = \"cpu\"\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0.9)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(loss_function, optimizer, device)\n",
    "trainer.train_loop(cnn, train_loader, val_loader)\n",
    "trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc4b6999490>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FIG_X[:len(LOSS)], LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Train 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS_TRAIN: []\n",
      "ACC_TRAIN: []\n",
      "ACC_TEST: []\n",
      "X: []\n"
     ]
    }
   ],
   "source": [
    "LOSS_TRAIN=[]\n",
    "ACC_TRAIN=[]\n",
    "ACC_TEST=[]\n",
    "X=[]\n",
    "flag=0\n",
    "print(\"LOSS_TRAIN:\", LOSS_TRAIN)\n",
    "print(\"ACC_TRAIN:\",ACC_TRAIN)\n",
    "print(\"ACC_TEST:\",ACC_TEST)\n",
    "print(\"X:\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Epoch 0 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.294 Acc 0.219\n",
      "[  1/1] Training Step 100 Loss 2.299 Acc 0.312\n",
      "[  1/1] Training Step 200 Loss 2.294 Acc 0.312\n",
      "[  1/1] Training Step 300 Loss 2.294 Acc 0.344\n",
      "[  1/1] Training Step 400 Loss 2.289 Acc 0.344\n",
      "[  1/1] Training Step 500 Loss 2.285 Acc 0.438\n",
      "[  1/1] Training Step 600 Loss 2.293 Acc 0.312\n",
      "[  1/1] Training Step 700 Loss 2.282 Acc 0.469\n",
      "[  1/1] Training Step 800 Loss 2.286 Acc 0.250\n",
      "[  1/1] Training Step 900 Loss 2.282 Acc 0.344\n",
      "[  1/1] Training Step 1000 Loss 2.267 Acc 0.594\n",
      "[  1/1] Training Step 1100 Loss 2.278 Acc 0.375\n",
      "[  1/1] Training Step 1200 Loss 2.261 Acc 0.562\n",
      "[  1/1] Training Step 1300 Loss 2.271 Acc 0.438\n",
      "[  1/1] Training Step 1400 Loss 2.254 Acc 0.500\n",
      "[  1/1] Training Step 1500 Loss 2.262 Acc 0.531\n",
      "[  1/1] Validate Step 312 Loss 2.250 Acc 0.561\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 2.250 Acc 0.562\n",
      "---------------- Epoch 1 ----------------\n",
      "[  1/1] Training Step 000 Loss 2.258 Acc 0.469\n",
      "[  1/1] Training Step 100 Loss 2.248 Acc 0.594\n",
      "[  1/1] Training Step 200 Loss 2.238 Acc 0.531\n",
      "[  1/1] Training Step 300 Loss 2.216 Acc 0.719\n",
      "[  1/1] Training Step 400 Loss 2.212 Acc 0.531\n",
      "[  1/1] Training Step 500 Loss 2.219 Acc 0.625\n",
      "[  1/1] Training Step 600 Loss 2.202 Acc 0.500\n",
      "[  1/1] Training Step 700 Loss 2.213 Acc 0.562\n",
      "[  1/1] Training Step 800 Loss 2.168 Acc 0.562\n",
      "[  1/1] Training Step 900 Loss 2.155 Acc 0.531\n",
      "[  1/1] Training Step 1000 Loss 2.172 Acc 0.469\n",
      "[  1/1] Training Step 1100 Loss 2.147 Acc 0.469\n",
      "[  1/1] Training Step 1200 Loss 2.116 Acc 0.656\n",
      "[  1/1] Training Step 1300 Loss 2.015 Acc 0.656\n",
      "[  1/1] Training Step 1400 Loss 2.002 Acc 0.750\n",
      "[  1/1] Training Step 1500 Loss 2.070 Acc 0.594\n",
      "[  1/1] Validate Step 312 Loss 1.940 Acc 0.714\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 1.937 Acc 0.701\n",
      "---------------- Epoch 2 ----------------\n",
      "[  1/1] Training Step 000 Loss 1.984 Acc 0.562\n",
      "[  1/1] Training Step 100 Loss 1.809 Acc 0.625\n",
      "[  1/1] Training Step 200 Loss 1.793 Acc 0.656\n",
      "[  1/1] Training Step 300 Loss 1.725 Acc 0.781\n",
      "[  1/1] Training Step 400 Loss 1.581 Acc 0.781\n",
      "[  1/1] Training Step 500 Loss 1.394 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 1.408 Acc 0.750\n",
      "[  1/1] Training Step 700 Loss 1.259 Acc 0.781\n",
      "[  1/1] Training Step 800 Loss 1.300 Acc 0.719\n",
      "[  1/1] Training Step 900 Loss 1.025 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.930 Acc 0.844\n",
      "[  1/1] Training Step 1100 Loss 1.007 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 1.059 Acc 0.750\n",
      "[  1/1] Training Step 1300 Loss 0.707 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.944 Acc 0.719\n",
      "[  1/1] Training Step 1500 Loss 0.665 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.683 Acc 0.842\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.690 Acc 0.833\n",
      "---------------- Epoch 3 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.478 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.703 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.603 Acc 0.844\n",
      "[  1/1] Training Step 300 Loss 0.665 Acc 0.844\n",
      "[  1/1] Training Step 400 Loss 0.652 Acc 0.781\n",
      "[  1/1] Training Step 500 Loss 0.594 Acc 0.812\n",
      "[  1/1] Training Step 600 Loss 0.486 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.740 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.584 Acc 0.875\n",
      "[  1/1] Training Step 900 Loss 0.474 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.415 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.434 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.518 Acc 0.781\n",
      "[  1/1] Training Step 1300 Loss 0.491 Acc 0.781\n",
      "[  1/1] Training Step 1400 Loss 0.327 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.549 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.436 Acc 0.878\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.449 Acc 0.878\n",
      "---------------- Epoch 4 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.481 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.608 Acc 0.781\n",
      "[  1/1] Training Step 200 Loss 0.438 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.446 Acc 0.812\n",
      "[  1/1] Training Step 400 Loss 0.344 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.405 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.308 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.637 Acc 0.844\n",
      "[  1/1] Training Step 800 Loss 0.491 Acc 0.844\n",
      "[  1/1] Training Step 900 Loss 0.268 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.468 Acc 0.812\n",
      "[  1/1] Training Step 1100 Loss 0.510 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.417 Acc 0.812\n",
      "[  1/1] Training Step 1300 Loss 0.520 Acc 0.781\n",
      "[  1/1] Training Step 1400 Loss 0.309 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.412 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.371 Acc 0.891\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.384 Acc 0.890\n",
      "---------------- Epoch 5 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.322 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.456 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.260 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.172 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.193 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.423 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.324 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.436 Acc 0.812\n",
      "[  1/1] Training Step 800 Loss 0.369 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.298 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.422 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.219 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.476 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.378 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.288 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.224 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.341 Acc 0.899\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.350 Acc 0.898\n",
      "---------------- Epoch 6 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.232 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.322 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.183 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.296 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.310 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.345 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.328 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.174 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.506 Acc 0.812\n",
      "[  1/1] Training Step 900 Loss 0.572 Acc 0.844\n",
      "[  1/1] Training Step 1000 Loss 0.433 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.197 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.267 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.300 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.492 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.415 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.314 Acc 0.907\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.324 Acc 0.905\n",
      "---------------- Epoch 7 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.242 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.150 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.306 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.197 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.153 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.217 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.458 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.285 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.166 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.268 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.711 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.223 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.655 Acc 0.844\n",
      "[  1/1] Training Step 1300 Loss 0.550 Acc 0.844\n",
      "[  1/1] Training Step 1400 Loss 0.139 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.228 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.297 Acc 0.914\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.305 Acc 0.912\n",
      "---------------- Epoch 8 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.263 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.348 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.232 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.326 Acc 0.844\n",
      "[  1/1] Training Step 400 Loss 0.276 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.339 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.188 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.490 Acc 0.875\n",
      "[  1/1] Training Step 800 Loss 0.315 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.208 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.363 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.248 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.386 Acc 0.875\n",
      "[  1/1] Training Step 1300 Loss 0.282 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.223 Acc 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1500 Loss 0.520 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.281 Acc 0.920\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.286 Acc 0.917\n",
      "---------------- Epoch 9 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.349 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.430 Acc 0.844\n",
      "[  1/1] Training Step 200 Loss 0.253 Acc 0.844\n",
      "[  1/1] Training Step 300 Loss 0.178 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.356 Acc 0.844\n",
      "[  1/1] Training Step 500 Loss 0.463 Acc 0.812\n",
      "[  1/1] Training Step 600 Loss 0.177 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.089 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.337 Acc 0.875\n",
      "[  1/1] Training Step 900 Loss 0.236 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.312 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.242 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.263 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.153 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.181 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.246 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.264 Acc 0.924\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.268 Acc 0.922\n",
      "---------------- Epoch 10 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.210 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.154 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.203 Acc 0.875\n",
      "[  1/1] Training Step 300 Loss 0.173 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.108 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.568 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.305 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.204 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.207 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.253 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.292 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.492 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.502 Acc 0.781\n",
      "[  1/1] Training Step 1300 Loss 0.323 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.246 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.173 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.250 Acc 0.927\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.254 Acc 0.927\n",
      "---------------- Epoch 11 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.178 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.269 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.373 Acc 0.812\n",
      "[  1/1] Training Step 300 Loss 0.853 Acc 0.844\n",
      "[  1/1] Training Step 400 Loss 0.164 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.413 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.250 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.101 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.260 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.601 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.392 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.139 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.170 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.058 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.148 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.238 Acc 0.933\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.241 Acc 0.930\n",
      "---------------- Epoch 12 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.217 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.485 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.452 Acc 0.844\n",
      "[  1/1] Training Step 300 Loss 0.406 Acc 0.844\n",
      "[  1/1] Training Step 400 Loss 0.160 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.221 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.299 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.103 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.173 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.301 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.577 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.292 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.154 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.233 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.281 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.234 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.230 Acc 0.934\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.228 Acc 0.934\n",
      "---------------- Epoch 13 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.511 Acc 0.844\n",
      "[  1/1] Training Step 100 Loss 0.344 Acc 0.875\n",
      "[  1/1] Training Step 200 Loss 0.392 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.256 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.160 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.279 Acc 0.844\n",
      "[  1/1] Training Step 600 Loss 0.170 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.127 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.098 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.073 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.325 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.400 Acc 0.844\n",
      "[  1/1] Training Step 1500 Loss 0.253 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.217 Acc 0.937\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.217 Acc 0.936\n",
      "---------------- Epoch 14 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.161 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.255 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.175 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.223 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.259 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.159 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.308 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.147 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.327 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.179 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.099 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.124 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.208 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.099 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.165 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.208 Acc 0.939\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.208 Acc 0.939\n",
      "---------------- Epoch 15 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.146 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.446 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.173 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.198 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.128 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.260 Acc 0.875\n",
      "[  1/1] Training Step 600 Loss 0.171 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.091 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.069 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.183 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.199 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.253 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.161 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.221 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.205 Acc 0.942\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.202 Acc 0.941\n",
      "---------------- Epoch 16 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.277 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.399 Acc 0.781\n",
      "[  1/1] Training Step 200 Loss 0.156 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.109 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.106 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.203 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.134 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.301 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.090 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.558 Acc 0.781\n",
      "[  1/1] Training Step 1100 Loss 0.348 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.266 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.175 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.039 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.192 Acc 0.945\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.192 Acc 0.943\n",
      "---------------- Epoch 17 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.205 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.345 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.179 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.087 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.230 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.220 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.215 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.157 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.193 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.295 Acc 0.906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 1100 Loss 0.414 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.212 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.176 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.060 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.184 Acc 0.949\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.183 Acc 0.947\n",
      "---------------- Epoch 18 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.343 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.100 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.179 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.243 Acc 0.875\n",
      "[  1/1] Training Step 400 Loss 0.057 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.316 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.088 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.146 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.237 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.189 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.114 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.093 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.179 Acc 0.950\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.179 Acc 0.948\n",
      "---------------- Epoch 19 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.115 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.074 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.145 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.397 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.184 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.313 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.135 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.272 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.372 Acc 0.875\n",
      "[  1/1] Training Step 1100 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.243 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.384 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.156 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.088 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.173 Acc 0.953\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.171 Acc 0.950\n",
      "---------------- Epoch 20 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.149 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.258 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.264 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.065 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.049 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.149 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.210 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.236 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.153 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.162 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.189 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.122 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.120 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.059 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.167 Acc 0.955\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.165 Acc 0.952\n",
      "---------------- Epoch 21 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.084 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.193 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.212 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.144 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.374 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.093 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.112 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.104 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.164 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.260 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.336 Acc 0.812\n",
      "[  1/1] Training Step 1500 Loss 0.379 Acc 0.844\n",
      "[  1/1] Validate Step 312 Loss 0.162 Acc 0.955\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.158 Acc 0.954\n",
      "---------------- Epoch 22 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.524 Acc 0.812\n",
      "[  1/1] Training Step 200 Loss 0.120 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.315 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.087 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.220 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.191 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.129 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.159 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.130 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.193 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.126 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.319 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.272 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.066 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.159 Acc 0.956\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.156 Acc 0.955\n",
      "---------------- Epoch 23 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.100 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.225 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.119 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.108 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.204 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.159 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.309 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.069 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.055 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.153 Acc 0.957\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.151 Acc 0.956\n",
      "---------------- Epoch 24 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.264 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.417 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.227 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.063 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.082 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.320 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.103 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.072 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.412 Acc 0.875\n",
      "[  1/1] Training Step 900 Loss 0.087 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.224 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.063 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.123 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.081 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.074 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.148 Acc 0.958\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.144 Acc 0.959\n",
      "---------------- Epoch 25 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.069 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.143 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.125 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.078 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.124 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.119 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.460 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.120 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.058 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.062 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.074 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.331 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.086 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.147 Acc 0.958\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.143 Acc 0.958\n",
      "---------------- Epoch 26 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.111 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.171 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.098 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.176 Acc 0.938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 700 Loss 0.028 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.167 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.173 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.084 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.380 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.176 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.192 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.140 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.137 Acc 0.961\n",
      "---------------- Epoch 27 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.160 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.307 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.152 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.151 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.144 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.166 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.111 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.136 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.094 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.189 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.136 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.134 Acc 0.962\n",
      "---------------- Epoch 28 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.211 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.089 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.192 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.062 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.245 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.348 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.194 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.116 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.262 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.263 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.134 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.132 Acc 0.962\n",
      "---------------- Epoch 29 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.133 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.065 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.113 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.064 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.054 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.143 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.137 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.313 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.090 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.200 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.063 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.048 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.131 Acc 0.962\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.128 Acc 0.963\n",
      "---------------- Epoch 30 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.224 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.150 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.285 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.213 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.271 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.084 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.155 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.127 Acc 0.963\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.124 Acc 0.964\n",
      "---------------- Epoch 31 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.124 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.256 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.070 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.361 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.302 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.076 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.187 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.216 Acc 0.906\n",
      "[  1/1] Training Step 1000 Loss 0.197 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.296 Acc 0.906\n",
      "[  1/1] Training Step 1200 Loss 0.127 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.356 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.179 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.031 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.125 Acc 0.964\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.122 Acc 0.965\n",
      "---------------- Epoch 32 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.188 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.119 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.244 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.264 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.235 Acc 0.906\n",
      "[  1/1] Training Step 1100 Loss 0.150 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.112 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.150 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.040 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.123 Acc 0.965\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.120 Acc 0.965\n",
      "---------------- Epoch 33 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.073 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.089 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.049 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.200 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.226 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.062 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 1000 Loss 0.130 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.339 Acc 0.875\n",
      "[  1/1] Training Step 1200 Loss 0.117 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.061 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.146 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.119 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.118 Acc 0.965\n",
      "---------------- Epoch 34 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.042 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.253 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.207 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.046 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.118 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.272 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.091 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.117 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.067 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.157 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.211 Acc 0.875\n",
      "[  1/1] Training Step 1500 Loss 0.228 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.118 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Epoch 35 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.098 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.054 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.062 Acc 0.969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Training Step 300 Loss 0.141 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.126 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.255 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.134 Acc 0.969\n",
      "[  1/1] Training Step 700 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.064 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.047 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.230 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.341 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.154 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.089 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.199 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.117 Acc 0.967\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Epoch 36 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.136 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.236 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.137 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.150 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.060 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.071 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.120 Acc 0.906\n",
      "[  1/1] Training Step 900 Loss 0.006 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.102 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.121 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.071 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.054 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.118 Acc 0.967\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.118 Acc 0.964\n",
      "---------------- Epoch 37 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.151 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.319 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.376 Acc 0.906\n",
      "[  1/1] Training Step 300 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.241 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.164 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.193 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.068 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.071 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.162 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.301 Acc 0.906\n",
      "[  1/1] Training Step 1500 Loss 0.046 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.116 Acc 0.966\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.115 Acc 0.966\n",
      "---------------- Epoch 38 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.091 Acc 0.938\n",
      "[  1/1] Training Step 100 Loss 0.207 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.066 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.220 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.254 Acc 0.906\n",
      "[  1/1] Training Step 600 Loss 0.208 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.058 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.010 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.049 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.074 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.182 Acc 0.938\n",
      "[  1/1] Validate Step 312 Loss 0.111 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.108 Acc 0.968\n",
      "---------------- Epoch 39 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.263 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.312 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.016 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.080 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.118 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.110 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.115 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.161 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.058 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.072 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.058 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.108 Acc 0.968\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.106 Acc 0.968\n",
      "---------------- Epoch 40 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.020 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.095 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.117 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.069 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.196 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.169 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.118 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.098 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.218 Acc 0.938\n",
      "[  1/1] Training Step 1200 Loss 0.117 Acc 0.906\n",
      "[  1/1] Training Step 1300 Loss 0.076 Acc 0.938\n",
      "[  1/1] Training Step 1400 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.037 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.107 Acc 0.969\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.105 Acc 0.970\n",
      "---------------- Epoch 41 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.041 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.241 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.024 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.074 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.055 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.029 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.117 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.045 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.160 Acc 0.906\n",
      "[  1/1] Training Step 1400 Loss 0.042 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.295 Acc 0.875\n",
      "[  1/1] Validate Step 312 Loss 0.103 Acc 0.970\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.101 Acc 0.971\n",
      "---------------- Epoch 42 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.260 Acc 0.906\n",
      "[  1/1] Training Step 100 Loss 0.057 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.075 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.046 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.040 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.079 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.488 Acc 0.875\n",
      "[  1/1] Training Step 700 Loss 0.144 Acc 0.938\n",
      "[  1/1] Training Step 800 Loss 0.070 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.093 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.043 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.089 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.077 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.365 Acc 0.906\n",
      "[  1/1] Validate Step 312 Loss 0.104 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.102 Acc 0.970\n",
      "---------------- Epoch 43 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.009 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.023 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.352 Acc 0.906\n",
      "[  1/1] Training Step 500 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.351 Acc 0.906\n",
      "[  1/1] Training Step 700 Loss 0.140 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.091 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.059 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.045 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.056 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.065 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.021 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.051 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.233 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.105 Acc 0.970\n",
      "---------------- Testing ----------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/1] Testing Step 312 Loss 0.101 Acc 0.969\n",
      "---------------- Epoch 44 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.112 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.136 Acc 0.906\n",
      "[  1/1] Training Step 200 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.107 Acc 0.969\n",
      "[  1/1] Training Step 500 Loss 0.053 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.369 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.084 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.106 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.148 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.299 Acc 0.938\n",
      "[  1/1] Training Step 1300 Loss 0.171 Acc 0.875\n",
      "[  1/1] Training Step 1400 Loss 0.166 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.048 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.099 Acc 0.972\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.097 Acc 0.972\n",
      "---------------- Epoch 45 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.067 Acc 0.969\n",
      "[  1/1] Training Step 100 Loss 0.044 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.011 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.022 Acc 1.000\n",
      "[  1/1] Training Step 400 Loss 0.050 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.127 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.115 Acc 0.938\n",
      "[  1/1] Training Step 700 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.160 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.061 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.060 Acc 1.000\n",
      "[  1/1] Training Step 1400 Loss 0.144 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.030 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.100 Acc 0.972\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.097 Acc 0.971\n",
      "---------------- Epoch 46 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.133 Acc 0.938\n",
      "[  1/1] Training Step 200 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.204 Acc 0.938\n",
      "[  1/1] Training Step 400 Loss 0.153 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.037 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.012 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.438 Acc 0.875\n",
      "[  1/1] Training Step 1000 Loss 0.133 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.123 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.138 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.097 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.064 Acc 0.969\n",
      "[  1/1] Training Step 1500 Loss 0.032 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.102 Acc 0.970\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.098 Acc 0.970\n",
      "---------------- Epoch 47 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.025 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.085 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.162 Acc 0.938\n",
      "[  1/1] Training Step 300 Loss 0.042 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.158 Acc 0.938\n",
      "[  1/1] Training Step 500 Loss 0.034 Acc 1.000\n",
      "[  1/1] Training Step 600 Loss 0.019 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.035 Acc 1.000\n",
      "[  1/1] Training Step 800 Loss 0.158 Acc 0.969\n",
      "[  1/1] Training Step 900 Loss 0.105 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.087 Acc 0.938\n",
      "[  1/1] Training Step 1100 Loss 0.086 Acc 0.969\n",
      "[  1/1] Training Step 1200 Loss 0.083 Acc 0.969\n",
      "[  1/1] Training Step 1300 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.094 Acc 0.938\n",
      "[  1/1] Training Step 1500 Loss 0.223 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.098 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.096 Acc 0.971\n",
      "---------------- Epoch 48 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.015 Acc 1.000\n",
      "[  1/1] Training Step 100 Loss 0.070 Acc 0.969\n",
      "[  1/1] Training Step 200 Loss 0.063 Acc 0.969\n",
      "[  1/1] Training Step 300 Loss 0.238 Acc 0.906\n",
      "[  1/1] Training Step 400 Loss 0.048 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.156 Acc 0.969\n",
      "[  1/1] Training Step 600 Loss 0.072 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.176 Acc 0.906\n",
      "[  1/1] Training Step 800 Loss 0.017 Acc 1.000\n",
      "[  1/1] Training Step 900 Loss 0.056 Acc 0.969\n",
      "[  1/1] Training Step 1000 Loss 0.075 Acc 0.969\n",
      "[  1/1] Training Step 1100 Loss 0.111 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.027 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.162 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.026 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.008 Acc 1.000\n",
      "[  1/1] Validate Step 312 Loss 0.099 Acc 0.971\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.097 Acc 0.970\n",
      "---------------- Epoch 49 ----------------\n",
      "[  1/1] Training Step 000 Loss 0.456 Acc 0.875\n",
      "[  1/1] Training Step 100 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 200 Loss 0.014 Acc 1.000\n",
      "[  1/1] Training Step 300 Loss 0.104 Acc 0.969\n",
      "[  1/1] Training Step 400 Loss 0.030 Acc 1.000\n",
      "[  1/1] Training Step 500 Loss 0.135 Acc 0.938\n",
      "[  1/1] Training Step 600 Loss 0.036 Acc 1.000\n",
      "[  1/1] Training Step 700 Loss 0.037 Acc 0.969\n",
      "[  1/1] Training Step 800 Loss 0.218 Acc 0.938\n",
      "[  1/1] Training Step 900 Loss 0.052 Acc 1.000\n",
      "[  1/1] Training Step 1000 Loss 0.039 Acc 1.000\n",
      "[  1/1] Training Step 1100 Loss 0.008 Acc 1.000\n",
      "[  1/1] Training Step 1200 Loss 0.038 Acc 1.000\n",
      "[  1/1] Training Step 1300 Loss 0.069 Acc 0.969\n",
      "[  1/1] Training Step 1400 Loss 0.005 Acc 1.000\n",
      "[  1/1] Training Step 1500 Loss 0.175 Acc 0.969\n",
      "[  1/1] Validate Step 312 Loss 0.095 Acc 0.972\n",
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.096 Acc 0.972\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "optimizer = torch.optim.SGD(params=cnn.parameters(),lr=LEARNING_RATE, momentum=0)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for i in range(0, 50):\n",
    "    print(\"---------------- Epoch {} ----------------\".format(i))\n",
    "    trainer = Trainer(loss_function, optimizer, device)\n",
    "    trainer.train_loop(cnn, train_loader, val_loader)\n",
    "    trainer.test(cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn.state_dict(), \"./model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10), num='5.4 Training Result')\n",
    "plt.subplot(211)\n",
    "plt.plot(FIG_X[0:len(ACC_TRAIN)], ACC_TRAIN, label=\"Training\")\n",
    "plt.plot(FIG_X[0:len(ACC_TEST)], ACC_TEST, label=\"Testing\")\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(FIG_X[0:len(LOSS_TRAIN)], LOSS_TRAIN)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc1): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=200, bias=False)\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (fc2): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=10, bias=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(\"./model\"))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Testing ----------------\n",
      "[  1/1] Testing Step 312 Loss 0.096 Acc 0.972\n"
     ]
    }
   ],
   "source": [
    "trainer.test(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "testIndex = 0\n",
    "print(testIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chienchia/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: Matplotlib is currently using module://ipykernel.pylab.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14, 6), num='5.5')\n",
    "TEST_IMAGE, test_image_label = test_data[testIndex]\n",
    "test_image = np.array(TEST_IMAGE, dtype='float')\n",
    "pixels = test_image.reshape((28, 28))\n",
    "fig.add_subplot(1, 2, 1)\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "fig.show()\n",
    "\n",
    "# Test Model\n",
    "model.eval()\n",
    "test = DataLoader(test_data[testIndex])\n",
    "test_x, test_y = test\n",
    "output = model(test_x)\n",
    "output = output.tolist()[0]\n",
    "maxElement = max(output)\n",
    "outputProb = []\n",
    "outputProbLabel = []\n",
    "for item in output:\n",
    "    if item == maxElement:\n",
    "        outputProb.append(1)\n",
    "    else:\n",
    "        outputProb.append(0)\n",
    "    outputProbLabel.append(output.index(item))\n",
    "fig.add_subplot(1, 2, 2)\n",
    "plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "plt.bar(outputProbLabel, outputProb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
